{"meta":{"version":1,"warehouse":"3.0.2"},"models":{"Asset":[{"_id":"themes/edinburgh/source/css/styles.css","path":"css/styles.css","modified":1,"renderable":1},{"_id":"themes/edinburgh/source/images/unsplash.jpg","path":"images/unsplash.jpg","modified":1,"renderable":1},{"_id":"themes/edinburgh/source/images/screenshot.png","path":"images/screenshot.png","modified":0,"renderable":1},{"_id":"themes/edinburgh/source/images/style-transfer.jpg","path":"images/style-transfer.jpg","modified":0,"renderable":1},{"_id":"themes/edinburgh/source/images/jardin-sonoro.jpg","path":"images/jardin-sonoro.jpg","modified":0,"renderable":1},{"_id":"themes/edinburgh/source/images/poetry.jpg","path":"images/poetry.jpg","modified":0,"renderable":1},{"_id":"themes/edinburgh/source/images/bu3namigue.jpg","path":"images/bu3namigue.jpg","modified":0,"renderable":1},{"_id":"themes/edinburgh/source/images/automata.gif","path":"images/automata.gif","modified":0,"renderable":1},{"_id":"themes/edinburgh/source/images/physarum.gif","path":"images/physarum.gif","modified":0,"renderable":1},{"_id":"themes/edinburgh/source/images/pattern.png","path":"images/pattern.png","modified":0,"renderable":1},{"_id":"themes/edinburgh/source/images/shallow.jpg","path":"images/shallow.jpg","modified":0,"renderable":1},{"_id":"themes/edinburgh/source/images/emotiv.png","path":"images/emotiv.png","modified":1,"renderable":1},{"_id":"themes/edinburgh/source/images/live-voice.jpg","path":"images/live-voice.jpg","modified":0,"renderable":1},{"_id":"themes/edinburgh/source/images/psychological.jpg","path":"images/psychological.jpg","modified":0,"renderable":1},{"_id":"themes/edinburgh/source/images/pattern2.jpg","path":"images/pattern2.jpg","modified":0,"renderable":1},{"_id":"themes/edinburgh/source/favicon/favicon.png","path":"favicon/favicon.png","modified":0,"renderable":1}],"Cache":[{"_id":"themes/anatole/.gitignore","hash":"9fcbb05b158b5d3ba1ee60d38889e05e8b0f3f2a","modified":1585704166575},{"_id":"themes/anatole/LICENSE","hash":"359cb81298c1fdbccf531548fc097466b0151be4","modified":1585704166575},{"_id":"themes/anatole/README.md","hash":"88d58e69eda2435ce074bc6cafb1817346089a88","modified":1585704166575},{"_id":"themes/anatole/_config.sample.yml","hash":"c6bce49d93a37e9ed5f0c4b104decc0bd7832e04","modified":1585704166575},{"_id":"themes/anatole/package.json","hash":"cf731a3ebf3913747fccb6c4c6615eba7d7e88a4","modified":1585704166575},{"_id":"source/_posts/hello-world.md","hash":"f2dfa89600b7a4b330492cea174511be89aa615d","modified":1585752124339},{"_id":"themes/anatole/languages/pt-BR.yml","hash":"ac5a0003d7793aade51f70643b2e2a631b6a65c3","modified":1585704166575},{"_id":"themes/anatole/languages/zh-cn.yml","hash":"dab1823e036f4adb3b7ae9efe95a37a15e47bec2","modified":1585704166575},{"_id":"themes/anatole/layout/archive.pug","hash":"1a161404966000b25a84762f08da3ca60af146bc","modified":1585704166575},{"_id":"themes/anatole/layout/category.pug","hash":"ae894ef4baee4a0c7c8e66641166061e789f1fa7","modified":1585704166575},{"_id":"themes/anatole/layout/index.pug","hash":"53da3cfd498951148acb33de1574df80ae282dc5","modified":1585704166575},{"_id":"themes/anatole/layout/mixins.pug","hash":"107bfd2fe10de0d8b110c13bb1168af79e62a37c","modified":1585704166575},{"_id":"themes/anatole/layout/page.pug","hash":"15142c94e5c2247aba8efb64cffd695b3f133670","modified":1585704166575},{"_id":"themes/anatole/layout/post.pug","hash":"012f8e272cf4713a0f08e3b702dab08ef6593b31","modified":1585704166575},{"_id":"themes/anatole/layout/tag.pug","hash":"7017a8bae4f4a412dafb556772bdcf2cfddeb79f","modified":1585704166575},{"_id":"themes/anatole/layout/partial/comments.pug","hash":"fad5bbe7c2a134c892fcb1c731d979463145a49b","modified":1585704166575},{"_id":"themes/anatole/layout/partial/footer.pug","hash":"772f03a2dd9fa4fed422c4eb4d5d1ace84c65580","modified":1585704166575},{"_id":"themes/anatole/layout/partial/head.pug","hash":"3d6126d0b53a889a46ad61eb8cc0ab1b35446c49","modified":1585704166575},{"_id":"themes/anatole/layout/partial/layout.pug","hash":"d06c97b36de345908a9b0c081d84aed9f655fd9d","modified":1585771846647},{"_id":"themes/anatole/layout/partial/nav.pug","hash":"03199bf8d18b419acb9779931007d182e782f18f","modified":1585867611168},{"_id":"themes/anatole/layout/partial/sidebar.pug","hash":"6721b1e0b1e59e54d031a4978e7f82aece336efc","modified":1585704166575},{"_id":"themes/anatole/source/css/blog_basic.css","hash":"7db88f0873e858b21a4c981c8481708ad9117478","modified":1585704166575},{"_id":"themes/anatole/source/css/font-awesome.min.css","hash":"95d0b0c4d11105c81be1857b744076a1d2bed918","modified":1585704166575},{"_id":"themes/anatole/source/css/style.css","hash":"5d49b84a107e508b5e63b4ac0b1c9f1900be93dc","modified":1585867877225},{"_id":"themes/anatole/source/css/style.scss","hash":"175c9237798207f705c62777b5f51509adec6d0a","modified":1585704166575},{"_id":"themes/anatole/source/fonts/fontawesome-webfont.eot","hash":"0183979056f0b87616cd99d5c54a48f3b771eee6","modified":1585704166575},{"_id":"themes/anatole/source/fonts/fontawesome-webfont.woff","hash":"7d65e0227d0d7cdc1718119cd2a7dce0638f151c","modified":1585704166579},{"_id":"themes/anatole/source/images/favicon.png","hash":"790e72ae1fc16ce1c33af13d19935ab6267eba38","modified":1586038703595},{"_id":"themes/anatole/source/images/logo.png","hash":"41bdf2ebd8cc193ad82a211758af827d891b1a90","modified":1585704166579},{"_id":"themes/anatole/source/images/logo@2x.png","hash":"49c3fa97724abf53861bf11356ea9ba5bcb11576","modified":1585704166579},{"_id":"themes/anatole/source/js/jquery-migrate-1.2.1.min.js","hash":"743052320809514fb788fe1d3df37fc87ce90452","modified":1585704166579},{"_id":"themes/anatole/source/js/jquery.appear.js","hash":"1f8067d7bd4c0bde30785e8016100f239e14394f","modified":1585704166579},{"_id":"themes/anatole/source/fonts/fontawesome-webfont.ttf","hash":"6225ccc4ec94d060f19efab97ca42d842845b949","modified":1585704166579},{"_id":"themes/anatole/source/js/jquery.js","hash":"bfc05b695dfa4f23e11d04b84993585da7a764bf","modified":1585704166579},{"_id":"themes/anatole/source/fonts/fontawesome-webfont.svg","hash":"cd980eab6db5fa57db670cb2e4278e67e1a4d6c9","modified":1585704166575},{"_id":"source/about/index.md","hash":"775440b97077eead5a3a5ae711091db614bce89d","modified":1587244742270},{"_id":"source/archives/index.md","hash":"c9ebba08584753c0b8c9d4a594accb436ae424b3","modified":1585751573156},{"_id":"source/links/index.md","hash":"afe5d6185c45ff602f25e8f1060571f9e790ac21","modified":1585756967952},{"_id":"themes/anatole/languages/en.yml","hash":"4d442c64e1c3f29771afc660dde378462a1c4606","modified":1586039085761},{"_id":"public/about/index.html","hash":"95ca69e63bb011eb0db2256714cc77873cf674a6","modified":1586038338230},{"_id":"public/archives/index.html","hash":"7e8e02725ea2c23d0dd93b6ef6f4ff525c6cd67b","modified":1586038338230},{"_id":"public/links/index.html","hash":"c68c34e95502844a1c8c0cf9dad0fedc1f8528be","modified":1586038338230},{"_id":"public/2020/04/01/hello-world/index.html","hash":"7aee267649879db2dfe5112e10efd9a1c54f8edc","modified":1585755865623},{"_id":"public/index.html","hash":"92f07b3fb8eee36955334871a2b044b82c5b8eac","modified":1586038338230},{"_id":"public/css/style.scss","hash":"175c9237798207f705c62777b5f51509adec6d0a","modified":1585771347540},{"_id":"public/fonts/fontawesome-webfont.eot","hash":"0183979056f0b87616cd99d5c54a48f3b771eee6","modified":1585771347540},{"_id":"public/images/favicon.png","hash":"790e72ae1fc16ce1c33af13d19935ab6267eba38","modified":1586038732191},{"_id":"public/images/logo.png","hash":"41bdf2ebd8cc193ad82a211758af827d891b1a90","modified":1585771347540},{"_id":"public/images/logo@2x.png","hash":"49c3fa97724abf53861bf11356ea9ba5bcb11576","modified":1585771347540},{"_id":"public/fonts/fontawesome-webfont.woff","hash":"7d65e0227d0d7cdc1718119cd2a7dce0638f151c","modified":1585771347540},{"_id":"public/fonts/fontawesome-webfont.ttf","hash":"6225ccc4ec94d060f19efab97ca42d842845b949","modified":1585771347540},{"_id":"public/css/blog_basic.css","hash":"7db88f0873e858b21a4c981c8481708ad9117478","modified":1585771347540},{"_id":"public/css/style.css","hash":"5d49b84a107e508b5e63b4ac0b1c9f1900be93dc","modified":1585867921346},{"_id":"public/js/jquery-migrate-1.2.1.min.js","hash":"743052320809514fb788fe1d3df37fc87ce90452","modified":1585771347540},{"_id":"public/js/jquery.appear.js","hash":"1f8067d7bd4c0bde30785e8016100f239e14394f","modified":1585771347540},{"_id":"public/css/font-awesome.min.css","hash":"95d0b0c4d11105c81be1857b744076a1d2bed918","modified":1585771347540},{"_id":"public/js/jquery.js","hash":"bfc05b695dfa4f23e11d04b84993585da7a764bf","modified":1585771347540},{"_id":"public/fonts/fontawesome-webfont.svg","hash":"cd980eab6db5fa57db670cb2e4278e67e1a4d6c9","modified":1585771347540},{"_id":"source/_posts/number2image.md","hash":"962ad4f8bec400c93e9374de641ed68428f4582d","modified":1587240395788},{"_id":"source/_posts/number2image/pattern.png","hash":"bfcf276e31b2d52e5294a0d0bb886da758b562f2","modified":1585756051396},{"_id":"public/2020/04/01/number2image/index.html","hash":"77fc45173d850adfba9ed0e0d1e107806ff28e8e","modified":1585867631383},{"_id":"public/2020/04/01/number2image/pattern.png","hash":"bfcf276e31b2d52e5294a0d0bb886da758b562f2","modified":1585771347540},{"_id":"source/jardin-sonoro/index.md","hash":"c339c01abae539bec2d912bdbc733311e12578ae","modified":1585757418186},{"_id":"source/_posts/Singing-Synthesis.md","hash":"40b502093edc5f65dd8ed9c3294e4b3a17df7c00","modified":1587240442093},{"_id":"source/_posts/jardin-sonoro.md","hash":"8388fab246bd048c6d5563ccab4e7361b181b55c","modified":1587235556042},{"_id":"themes/anatole/source/js/shader.js","hash":"7d1f7b15448bf9ab3b37c4c61e8e70d2472afef7","modified":1585771193020},{"_id":"source/_posts/jardin-sonoro/player.png","hash":"607e15d256b4e50cd3d1d9f6ceab76804615c3ea","modified":1585758372468},{"_id":"source/_posts/jardin-sonoro/inicio.png","hash":"1e1f7d5c7cae7e42a21b0e3e20ceb2bb82e1fadc","modified":1585758451406},{"_id":"source/_posts/jardin-sonoro/load.png","hash":"8ca07eaef8f075a910670654055475ec8d5e15c6","modified":1585757745593},{"_id":"public/2020/04/01/Singing-Synthesis/index.html","hash":"3db173a7dc6194179cf09aa7e976ec4e4a866b55","modified":1585867631383},{"_id":"public/2019/01/03/jardin-sonoro/index.html","hash":"4beb8c5fad89c21431986c79a32d8665cd4f570e","modified":1586038338230},{"_id":"public/2019/01/03/jardin-sonoro/player.png","hash":"607e15d256b4e50cd3d1d9f6ceab76804615c3ea","modified":1585771347540},{"_id":"public/js/shader.js","hash":"7d1f7b15448bf9ab3b37c4c61e8e70d2472afef7","modified":1585771347540},{"_id":"public/2019/01/03/jardin-sonoro/inicio.png","hash":"1e1f7d5c7cae7e42a21b0e3e20ceb2bb82e1fadc","modified":1585771347540},{"_id":"public/2019/01/03/jardin-sonoro/load.png","hash":"8ca07eaef8f075a910670654055475ec8d5e15c6","modified":1585771347540},{"_id":"source/_posts/AI-Poem-Writer.md","hash":"66605eeae38ba9915a28c1e75bef53c5fe4219a2","modified":1587236582660},{"_id":"source/_posts/Audio-Reactive-Slime.md","hash":"60bacb57178836ead1c014703e0c215cc9fca82f","modified":1587241213752},{"_id":"source/_posts/Midi-to-Voice.md","hash":"7dd9dc410b10212bce13dda7b353310cb8d9c20c","modified":1587235682319},{"_id":"source/_posts/Normalized-Google-Distance.md","hash":"3fb6703be3e583880011b0571dc4f4c1afb901cf","modified":1589073743841},{"_id":"source/_posts/Regenerative-cellular-automata.md","hash":"cca180ce3a53f76ad21ab6bd51bf8e02faf18bb4","modified":1589072782362},{"_id":"source/_posts/Scraping-formatted-text-from-images.md","hash":"aa6bf4ad3b17173d55785900bed75e2c4c317dae","modified":1589079035326},{"_id":"source/_posts/bu3nAmigue-Experimental-Indie-Band.md","hash":"d987ffe9fda44a161f3c088d5215f57a8173d66b","modified":1587235156510},{"_id":"source/_posts/Style-Transfer-Experiments.md","hash":"e8e5281ed57bd7a93d8e87ae0e2924794441ec44","modified":1587236675549},{"_id":"source/reviews/index.md","hash":"ffe5cc5ef42a8546adfaea504fb9fe3721661e60","modified":1586188010126},{"_id":"public/reviews/index.html","hash":"63d2f60c3e7845727d19ea7a89b4cb1ff0a76f8c","modified":1586038338230},{"_id":"public/2020/04/02/Regenerative-cellular-automata/index.html","hash":"46bb91e665d2401c88b769351dd1460739a66d17","modified":1585867631383},{"_id":"public/2020/04/02/Scraping-formatted-text-from-images/index.html","hash":"039eda95a814123e87778f16a028365e2558ef87","modified":1585867631383},{"_id":"public/2020/04/02/Normalized-Google-Distance/index.html","hash":"e829f8284ce5149fdb63d076ccb59561fe1b2947","modified":1585867631383},{"_id":"public/2020/04/02/AI-Poem-Writer/index.html","hash":"5295efd48b3b3dd155d48526751e9b92687c671d","modified":1585867631383},{"_id":"public/2020/04/02/bu3nAmigue-Experimental-Indie-Band/index.html","hash":"265a6f901f0701eaff7574407232affdf863d0e7","modified":1585867631383},{"_id":"public/2020/04/02/Midi-to-Voice/index.html","hash":"3a460554a31795be47719b720eb61c7a01932bf4","modified":1585867631383},{"_id":"public/2020/04/02/Style-Transfer-Experiments/index.html","hash":"28de2a86c4858f6d1194cf041879c0eda6c2b59b","modified":1585867631383},{"_id":"public/2020/04/02/Audio-Reactive-Slime/index.html","hash":"a34cba49dbf9c523cd1d66b458f2f6ad5f2ec6a7","modified":1585867631383},{"_id":"public/page/2/index.html","hash":"111c7a461f0017717958c9b9894f270ad28ca3d5","modified":1586038338230},{"_id":"source/reviews/index/iframe_height.js","hash":"4245eaba9341942b656b28138230cb810a9ce5ef","modified":1585870633225},{"_id":"public/reviews/index/iframe_height.js","hash":"4245eaba9341942b656b28138230cb810a9ce5ef","modified":1585871543201},{"_id":"source/_posts/Coding-Psychological-Experiments.md","hash":"f62e339b24d23a713e9982244a89a80f598e7b8f","modified":1587240977389},{"_id":"source/_posts/Computing-brain-connectivity-using-portable-devices-Master-s-Thesis.md","hash":"73fb1a6180dea9dae216fcae2beb5720467809e7","modified":1587240015910},{"_id":"source/_posts/Looking-for-the-beauty-formula.md","hash":"43081eca29ebac9888ba572cf712ba4919772eaa","modified":1587241324833},{"_id":"source/_posts/Scraping-drum-patterns-from-PDF.md","hash":"d77bbb6f3c3fefc93e33f8f6f8435b48cccd6c89","modified":1589073890732},{"_id":"source/_posts/AI-Poem-Writer/english3.jpg","hash":"a16013173af15c4f4260a8764c97b26934792eca","modified":1586034741748},{"_id":"source/_posts/AI-Poem-Writer/spanish1.jpg","hash":"38a6c8212230b45da28041539c701de2a8fe4d7c","modified":1586034780239},{"_id":"source/_posts/AI-Poem-Writer/spanish2.jpg","hash":"66663035a179be5012e4a1c79feadda0eb92b05f","modified":1586034777463},{"_id":"source/_posts/AI-Poem-Writer/spanish3.jpg","hash":"6df3668cb8bab723a2563455b555dc4cc9ec505c","modified":1586034774083},{"_id":"source/_posts/Audio-Reactive-Slime/physarum.jpg","hash":"a0d9991e8334d1f4e22dff04d25decdd48ce696f","modified":1586033422066},{"_id":"source/_posts/Midi-to-Voice/shallow.jpg","hash":"d2d8b69ab4c90ea7ba9d30163ecbdc4dcb732b77","modified":1586032851395},{"_id":"source/_posts/Computing-brain-connectivity-using-portable-devices-Master-s-Thesis/emotiv.jpg","hash":"43cc364622a072c5e6946d1cd0c62b81ad663a1a","modified":1586037559171},{"_id":"source/_posts/AI-Poem-Writer/english1.jpg","hash":"9562bb8d18e1f8edfdbc08d8e3c95aa7e3104cbb","modified":1586034770523},{"_id":"source/_posts/AI-Poem-Writer/english2.jpg","hash":"0bc0de5bffbf90d9257518770e9b14c271ebc269","modified":1586034765659},{"_id":"source/_posts/Audio-Reactive-Slime/physarum2.jpg","hash":"724cb8e960f7ea48cd14da16d17421aaf64c9d88","modified":1586033434118},{"_id":"source/_posts/Style-Transfer-Experiments/s1_1.jpg","hash":"38048f18357f46490e0dd0a4415b5bf3e7e14742","modified":1586036046341},{"_id":"source/_posts/Style-Transfer-Experiments/s1_2.jpg","hash":"1a92cead449c6b8536575a67a8089ddc6bcc20fd","modified":1586036063718},{"_id":"source/_posts/Style-Transfer-Experiments/s1_3.jpg","hash":"8432759683d38472b0164195933a72f2e398a8bc","modified":1586036066786},{"_id":"source/_posts/Style-Transfer-Experiments/s1_4.jpg","hash":"c4a164db4f1425be609bdbf77eac3aaf23304541","modified":1586036073899},{"_id":"source/_posts/Style-Transfer-Experiments/s2_4.jpg","hash":"2e17137eaba439cf2aa13ecd9c7bcf8cefdb913e","modified":1586036093948},{"_id":"source/_posts/Style-Transfer-Experiments/s2_1.jpg","hash":"8528221de84b2dd33c5d0a1897da8677c81d60f1","modified":1586036082635},{"_id":"source/_posts/Style-Transfer-Experiments/s3_2.jpg","hash":"f2c6897389095feedddac8eb56a19079b35960f4","modified":1586036102472},{"_id":"source/_posts/Style-Transfer-Experiments/s2_3.jpg","hash":"9f80e97f85c3bdf424ecc3f0403599a0984c86e2","modified":1586036090643},{"_id":"source/_posts/Style-Transfer-Experiments/s2_2.jpg","hash":"c213f306f70f2686f22fa9ce66f315826e08f5df","modified":1586036086307},{"_id":"source/_posts/Style-Transfer-Experiments/s4_2.jpg","hash":"3b38cb19c1adcad4e36ecfbe3a40d96175034d74","modified":1586036109361},{"_id":"source/_posts/Style-Transfer-Experiments/s3_1.jpg","hash":"45617811d73e223e806f8ae918c003f176b96391","modified":1586036099536},{"_id":"source/_posts/Style-Transfer-Experiments/s4_1.jpg","hash":"cb7d6f1f0bdba452dfa7db1694c7f8620199b829","modified":1586036105460},{"_id":"source/_posts/Regenerative-cellular-automata/automata2.gif","hash":"83a4cc0247ae57fd14548057f978b608412a879b","modified":1586035296618},{"_id":"source/_posts/Regenerative-cellular-automata/automata1.gif","hash":"e7dec8f3ad402fe695aecf06b74ed4862862a0ce","modified":1586035178812},{"_id":"public/2020/03/24/Regenerative-cellular-automata/index.html","hash":"5aaf1867f089a04bc8f9dc422ed89f23c0df068b","modified":1586038338230},{"_id":"public/2020/02/20/Scraping-drum-patterns-from-PDF/index.html","hash":"e6f0f797982b59be1773788f2d6032f3f20ec50f","modified":1586050397682},{"_id":"public/2020/01/21/AI-Poem-Writer/index.html","hash":"2e44e1fa7a6b1cf7c6e4210414b46cf83f33da68","modified":1586038338230},{"_id":"public/2019/12/31/Audio-Reactive-Slime/index.html","hash":"7dbb3406ae893cb2a46a47dfb761346c05a58588","modified":1586038338230},{"_id":"public/2019/12/29/Style-Transfer-Experiments/index.html","hash":"2b5b8cd279386fd4c25076cafe7fcf01259da34f","modified":1586038338230},{"_id":"public/2019/12/15/bu3nAmigue-Experimental-Indie-Band/index.html","hash":"0e226e4a355926b42d184806ec12215337c5dc0e","modified":1586038338230},{"_id":"public/2019/10/03/Scraping-formatted-text-from-images/index.html","hash":"b49c3912612d08ee7d5dd61ae72114642f9bcf72","modified":1586038338230},{"_id":"public/2019/08/05/Looking-for-the-beauty-formula/index.html","hash":"107143ac103ddc5ac174900eb875e5c3eb07e53b","modified":1586050397682},{"_id":"public/2019/06/09/Coding-Psychological-Experiments/index.html","hash":"e5f1a9b3b34c24e6bd38b32d1539634b329a8b8e","modified":1586050397682},{"_id":"public/2019/06/09/Normalized-Google-Distance/index.html","hash":"66cb041bc6263345e3f85113001655a1f8a94acb","modified":1586038338230},{"_id":"public/2019/06/07/number2image/index.html","hash":"d422dad10c46b6ee63fcda62c2d76b7d6a410150","modified":1586038338230},{"_id":"public/2019/05/05/Singing-Synthesis/index.html","hash":"4c68c34243e5e9914800b9023e42113825c0123a","modified":1586038338230},{"_id":"public/2018/06/10/Midi-to-Voice/index.html","hash":"9c1391ebe6837df2b70911d4a2c60542082b6c77","modified":1586038338230},{"_id":"public/2018/04/04/Computing-brain-connectivity-using-portable-devices-Master-s-Thesis/index.html","hash":"9d63cfbc36f7e98345b5b1b5610cb7785e9f45c5","modified":1586050397682},{"_id":"public/tags/poetry-gpt-2/index.html","hash":"ab9dd23dd88ec215470acd4449f2c005c6606c68","modified":1586038338230},{"_id":"public/tags/ocr/index.html","hash":"efdd24c75d4ac60c4544b7a1c4d01f7945585db7","modified":1586038338230},{"_id":"public/tags/style-transfer/index.html","hash":"5bf0c141ec47796e61f22a4341fad37b8e09d4af","modified":1586038338230},{"_id":"public/tags/cellular-automata/index.html","hash":"691fba45d8d673ad2915eed06f98f9192b5150a7","modified":1586038338230},{"_id":"public/tags/neuroscience/index.html","hash":"d926035ce5bf3509db08a7f731e08d4fecd4d1bd","modified":1586038338230},{"_id":"public/2019/12/31/Audio-Reactive-Slime/physarum.jpg","hash":"a0d9991e8334d1f4e22dff04d25decdd48ce696f","modified":1586038338230},{"_id":"public/2020/01/21/AI-Poem-Writer/english3.jpg","hash":"a16013173af15c4f4260a8764c97b26934792eca","modified":1586038338230},{"_id":"public/2020/01/21/AI-Poem-Writer/spanish3.jpg","hash":"6df3668cb8bab723a2563455b555dc4cc9ec505c","modified":1586038338230},{"_id":"public/2020/01/21/AI-Poem-Writer/spanish2.jpg","hash":"66663035a179be5012e4a1c79feadda0eb92b05f","modified":1586038338230},{"_id":"public/2020/01/21/AI-Poem-Writer/spanish1.jpg","hash":"38a6c8212230b45da28041539c701de2a8fe4d7c","modified":1586038338230},{"_id":"public/2018/04/04/Computing-brain-connectivity-using-portable-devices-Master-s-Thesis/emotiv.jpg","hash":"43cc364622a072c5e6946d1cd0c62b81ad663a1a","modified":1586038338230},{"_id":"public/2018/06/10/Midi-to-Voice/shallow.jpg","hash":"d2d8b69ab4c90ea7ba9d30163ecbdc4dcb732b77","modified":1586038338230},{"_id":"public/2019/12/31/Audio-Reactive-Slime/physarum2.jpg","hash":"724cb8e960f7ea48cd14da16d17421aaf64c9d88","modified":1586038338230},{"_id":"public/2020/01/21/AI-Poem-Writer/english2.jpg","hash":"0bc0de5bffbf90d9257518770e9b14c271ebc269","modified":1586038338230},{"_id":"public/2020/01/21/AI-Poem-Writer/english1.jpg","hash":"9562bb8d18e1f8edfdbc08d8e3c95aa7e3104cbb","modified":1586038338230},{"_id":"public/2019/12/29/Style-Transfer-Experiments/s1_2.jpg","hash":"1a92cead449c6b8536575a67a8089ddc6bcc20fd","modified":1586038338230},{"_id":"public/2019/12/29/Style-Transfer-Experiments/s1_3.jpg","hash":"8432759683d38472b0164195933a72f2e398a8bc","modified":1586038338230},{"_id":"public/2019/12/29/Style-Transfer-Experiments/s1_4.jpg","hash":"c4a164db4f1425be609bdbf77eac3aaf23304541","modified":1586038338230},{"_id":"public/2019/12/29/Style-Transfer-Experiments/s2_2.jpg","hash":"c213f306f70f2686f22fa9ce66f315826e08f5df","modified":1586038338230},{"_id":"public/2019/12/29/Style-Transfer-Experiments/s2_3.jpg","hash":"9f80e97f85c3bdf424ecc3f0403599a0984c86e2","modified":1586038338230},{"_id":"public/2019/12/29/Style-Transfer-Experiments/s2_4.jpg","hash":"2e17137eaba439cf2aa13ecd9c7bcf8cefdb913e","modified":1586038338230},{"_id":"public/2019/12/29/Style-Transfer-Experiments/s1_1.jpg","hash":"38048f18357f46490e0dd0a4415b5bf3e7e14742","modified":1586038338230},{"_id":"public/2019/12/29/Style-Transfer-Experiments/s2_1.jpg","hash":"8528221de84b2dd33c5d0a1897da8677c81d60f1","modified":1586038338230},{"_id":"public/2019/12/29/Style-Transfer-Experiments/s3_2.jpg","hash":"f2c6897389095feedddac8eb56a19079b35960f4","modified":1586038338230},{"_id":"public/2019/12/29/Style-Transfer-Experiments/s4_2.jpg","hash":"3b38cb19c1adcad4e36ecfbe3a40d96175034d74","modified":1586038338230},{"_id":"public/2019/12/29/Style-Transfer-Experiments/s3_1.jpg","hash":"45617811d73e223e806f8ae918c003f176b96391","modified":1586038338230},{"_id":"public/2019/12/29/Style-Transfer-Experiments/s4_1.jpg","hash":"cb7d6f1f0bdba452dfa7db1694c7f8620199b829","modified":1586038338230},{"_id":"public/2020/03/24/Regenerative-cellular-automata/automata2.gif","hash":"83a4cc0247ae57fd14548057f978b608412a879b","modified":1586038338230},{"_id":"public/2019/06/07/number2image/pattern.png","hash":"bfcf276e31b2d52e5294a0d0bb886da758b562f2","modified":1586038338230},{"_id":"public/2020/03/24/Regenerative-cellular-automata/automata1.gif","hash":"e7dec8f3ad402fe695aecf06b74ed4862862a0ce","modified":1586038338230},{"_id":"themes/Daily/README.md","hash":"7b169184b67d4efebbb60e68c244ea8bc4139983","modified":1586660547750},{"_id":"themes/Daily/_config.yml","hash":"74bf68631fae6969de1ba471b90d3ace5e6ff271","modified":1586663364162},{"_id":"themes/Daily/languages/default.yml","hash":"2df42359e6646c0c2903ada8411100a8f1d15134","modified":1586660547750},{"_id":"themes/Daily/languages/en.yml","hash":"2df42359e6646c0c2903ada8411100a8f1d15134","modified":1586660547750},{"_id":"themes/Daily/languages/zh-CN.yml","hash":"3e28e97eaf0e172ddee96b2d6f8ba604d90ff24d","modified":1586660547750},{"_id":"themes/Daily/languages/zh-TW.yml","hash":"c727b3550a12ad6f99b13e1b320466f8238f4b54","modified":1586660547750},{"_id":"themes/Daily/layout/archive.ejs","hash":"5afa6387ae87e15a4562822850806c51f471cbe8","modified":1586660547750},{"_id":"themes/Daily/layout/index.ejs","hash":"3317310e01719dd58878fb4b7bd1b41d495800af","modified":1586660547750},{"_id":"themes/Daily/layout/layout.ejs","hash":"cbdce5eecad781dd0cb8e0c6788a9bf5e9359800","modified":1586660547750},{"_id":"themes/Daily/layout/post.ejs","hash":"be2fe9171f1c8f15447b8fe6e69a82cd40a4dead","modified":1586660547750},{"_id":"themes/Daily/layout/tag.ejs","hash":"f13f991cdd2d462cfaff2ead0a110504e10d1d2f","modified":1586660547750},{"_id":"themes/Daily/layout/_partial/after-footer.ejs","hash":"00588b4db6aeec2d1f7951ee96980764a15e7f4f","modified":1586660547750},{"_id":"themes/Daily/layout/_partial/article-archive.ejs","hash":"32e6d38ac9074922f958126da4eb5cde0ae98da4","modified":1586660547750},{"_id":"themes/Daily/layout/_partial/article-index.ejs","hash":"017752ed1117edc33d22bb3b9e1db887a1e66f2d","modified":1586662747743},{"_id":"themes/Daily/layout/_partial/comment.ejs","hash":"9c8975d87fe1a1aad63cd74affa68f42ec3334e1","modified":1586660547750},{"_id":"themes/Daily/layout/_partial/footer.ejs","hash":"5f190a7233be1322e744fecd2759b8e8f7042be5","modified":1586660547750},{"_id":"themes/Daily/layout/_partial/head.ejs","hash":"9338cdc926aae79a50733e014e82471202b8fa07","modified":1586660547750},{"_id":"themes/Daily/layout/_partial/nav.ejs","hash":"cb5cb6371ad98a3fafb9d138a4f05b0b13a83edc","modified":1586660547750},{"_id":"themes/Daily/layout/_partial/pagination.ejs","hash":"98af75b95859dc6aae946497f27d7e51f753e5f6","modified":1586660547750},{"_id":"themes/Daily/source/css/_archive.scss","hash":"698f914f037079d1a25b9d86923eac4775b2ec7a","modified":1586660547754},{"_id":"themes/Daily/source/css/_comment.scss","hash":"8f92712c08489332c824d13e9e3d11bd2a0f1fd0","modified":1586660547754},{"_id":"themes/Daily/source/css/_daily.scss","hash":"e4261421d6c6af5b20c8e2b36353ea95cadb4eef","modified":1586660547754},{"_id":"themes/Daily/source/css/_highlight.scss","hash":"7d0bb75b74bea68dc04fa0346949d8f17fd28a0b","modified":1586660547754},{"_id":"themes/Daily/source/css/_mobile.scss","hash":"2b7297a4539e6ae803fe459ef411aa4149b24fcf","modified":1586660547754},{"_id":"themes/Daily/source/css/_nav.scss","hash":"eebe106b0360ea5d6735c59b524338faf0937d45","modified":1586660547754},{"_id":"themes/Daily/source/css/_normalize.scss","hash":"59fff706bed3120e3d9d6d0092a0372c172ee537","modified":1586660547754},{"_id":"themes/Daily/source/css/_post.scss","hash":"d674fd9312c33f98177ba8f7e144b2a663c60fd9","modified":1586660547754},{"_id":"themes/Daily/source/css/_variables.scss","hash":"508a896974912ccfdc4b14397df9fa4924d31dbf","modified":1586660547754},{"_id":"themes/Daily/source/css/style.scss","hash":"163cde007c7fb3debf9f53594c72d6536242f688","modified":1586660547754},{"_id":"themes/Daily/source/images/arrow-left.svg","hash":"4230dcb796a40d7a0f54c68e1ffb1f325ad962a5","modified":1586660547754},{"_id":"themes/Daily/source/images/arrow-right.svg","hash":"98c04bf1be3ca657f1e9697dc63219ade0a5616c","modified":1586660547754},{"_id":"themes/Daily/source/images/github.svg","hash":"bc2e3f2e54c354acfe64899482f6379d25f04792","modified":1586660547754},{"_id":"themes/Daily/source/images/mail.svg","hash":"18b3549b0447d605ca252fefcaa4d8e11179ce21","modified":1586660547754},{"_id":"themes/Daily/source/images/menu.svg","hash":"a1837ac76bc3e2aaf30450941bfefcb29ba16411","modified":1586660547754},{"_id":"themes/Daily/source/images/twitter.svg","hash":"2bef6c843de0113721c6c5d1676385897a22a446","modified":1586660547754},{"_id":"themes/Daily/source/images/weibo.svg","hash":"ffd43d8ae9f9ec4f5ae8b97cafa9023ac2a4e59b","modified":1586660547754},{"_id":"themes/Daily/source/js/app.js","hash":"b74710d1dd7b7d1407b4fcfc9499bc37de69b21e","modified":1586660547754},{"_id":"themes/edinburgh/_config.yml","hash":"f859f401966e0f5413e966b6a1516cad8b5491bf","modified":1586665142149},{"_id":"themes/edinburgh/README.md","hash":"5d45fa062dd9df69baf94932e7ffb998d9bbd311","modified":1586659303315},{"_id":"themes/edinburgh/layout/index.ejs","hash":"2948f26542a2766081e73e51a6285d692d806aa3","modified":1586659303315},{"_id":"themes/edinburgh/layout/layout.ejs","hash":"95bc999a70e479be9418934d92dab95b3c5cb3bf","modified":1586659303315},{"_id":"themes/edinburgh/layout/page.ejs","hash":"7dc2618940f52e280ba211274f21337aaee89eeb","modified":1586659303319},{"_id":"themes/edinburgh/layout/post.ejs","hash":"750b16c2137539c8ecbe0e9ae94d1d0bcd0b58cd","modified":1586659303319},{"_id":"themes/edinburgh/layout/_partial/footer.ejs","hash":"d6ab29e1d9e978a01b8a0894cd2e1a503f13b8d9","modified":1586659303315},{"_id":"themes/edinburgh/layout/_partial/google-analytics.ejs","hash":"148b6418f68d5b6c750d8443439739e64d31d30f","modified":1586659303315},{"_id":"themes/edinburgh/layout/_partial/head.ejs","hash":"45643f11eff2b6c1d72e2903bbcc0b2404e63efa","modified":1587244920445},{"_id":"themes/edinburgh/layout/_partial/header.ejs","hash":"2eddd1e42007f8f5ae6841811df4984f40d1afc6","modified":1586659303315},{"_id":"themes/edinburgh/layout/_partial/page-full.ejs","hash":"fef7efc86b2284e2038b80031201af817794d644","modified":1589070729138},{"_id":"themes/edinburgh/layout/_partial/portfolio-full.ejs","hash":"47a98334721fb11c55ab5ff73229e5990ef80a88","modified":1587238832176},{"_id":"themes/edinburgh/layout/_partial/portfolio-index.ejs","hash":"829a090fe2ddb6e15ea66c863b27c4819fd3eda9","modified":1589079122366},{"_id":"themes/edinburgh/source/css/styles.css","hash":"aa191e68a4828821310985be19604246574c46cc","modified":1589079359906},{"_id":"themes/edinburgh/source/favicon/favicon.ico","hash":"bc94003b0d5456fcf5ed1e1295233436a2d0fdfa","modified":1586659303319},{"_id":"themes/edinburgh/source/images/shallow.jpg","hash":"d2d8b69ab4c90ea7ba9d30163ecbdc4dcb732b77","modified":1586032851395},{"_id":"themes/edinburgh/source/images/pattern.png","hash":"a8161592a7877da35d16ae839d7d948db4bfc326","modified":1587239724714},{"_id":"themes/edinburgh/source/images/unsplash.jpg","hash":"f4de265dfe927b0de3b3b9ce317f2d229c360552","modified":1589073610526},{"_id":"themes/edinburgh/source/images/screenshot.png","hash":"ff903b2e54be65283799d38f8c26d8c4b08802ad","modified":1586659303323},{"_id":"themes/utone/.gitignore","hash":"58d26d4b5f2f94c2d02a4e4a448088e4a2527c77","modified":1586659314903},{"_id":"themes/utone/LICENSE","hash":"c480fce396b23997ee23cc535518ffaaf7f458f8","modified":1586659314903},{"_id":"themes/utone/_config.yml","hash":"33ae672bc61aa2e48d09d71095157b411e65781c","modified":1586659314903},{"_id":"themes/utone/README.md","hash":"8f1a25baafd789d0829ebd48f0175745d1fccbbe","modified":1586659314903},{"_id":"themes/utone/package.json","hash":"544f21a0b2c7034998b36ae94dba6e3e0f39f228","modified":1586659314903},{"_id":"themes/utone/languages/default.yml","hash":"fb8430db8a1f8a2e63ad81dd040db21fe30c8058","modified":1586659314903},{"_id":"themes/utone/languages/zh-CN.yml","hash":"4a0e470fa49806a7367696107fd9ffc6c3c08593","modified":1586659314903},{"_id":"themes/utone/layout/archive.ejs","hash":"448135d60396405f7979e349d92a9758dd62d354","modified":1586659314903},{"_id":"themes/utone/layout/layout.ejs","hash":"8165a0f6c02f86f04523ca23d651b2aabab00b5c","modified":1586659314903},{"_id":"themes/utone/layout/post.ejs","hash":"adce7970f59174f7dfdde6542f9390f6895c0439","modified":1586659314903},{"_id":"themes/utone/layout/index.ejs","hash":"db0c49c495ec90ddb1d935cac8f098053bbe0397","modified":1586661565115},{"_id":"themes/utone/source/css/highlight.styl","hash":"3c6ac6868c44c6c4653715ef90dcbf351641fed2","modified":1586659314903},{"_id":"themes/utone/source/css/pace.styl","hash":"8e50e39e8e285fed8ef8051e91b6ababf33fa05a","modified":1586659314903},{"_id":"themes/utone/source/css/site_search.styl","hash":"92b92193bb2228eefbc3e4c165e3c984623576a6","modified":1586659314903},{"_id":"themes/utone/source/css/style.styl","hash":"80bb8e196022e349c7f859f9856a3d2aef92b6e2","modified":1586659314903},{"_id":"themes/utone/source/images/close-circle.svg","hash":"61938c36e6bec7baf56f457c98752e708e246911","modified":1586659314903},{"_id":"themes/utone/source/images/favicon.ico","hash":"839746500e548c049538339add3e306e596057d2","modified":1586659314903},{"_id":"themes/utone/source/images/logo.png","hash":"ad6f5e25b1ae6b86cd1ab801ec575eeaa2f918ac","modified":1586659314903},{"_id":"themes/utone/source/images/search.svg","hash":"1e6bc3c869360be5bc6e70e2abfcdbfde5ea7154","modified":1586659314903},{"_id":"themes/utone/source/images/up-circle.svg","hash":"6cfa59db9844a8d00d3d9da09ddfcce62549d494","modified":1586659314903},{"_id":"themes/utone/source/scripts/utone.js","hash":"df4d33ed48ebad3556b38aee8da803e4cbe0678c","modified":1586659314903},{"_id":"themes/Daily/source/images/codementor.svg","hash":"2bef6c843de0113721c6c5d1676385897a22a446","modified":1586660547754},{"_id":"themes/Daily/source/images/favicon.png","hash":"790e72ae1fc16ce1c33af13d19935ab6267eba38","modified":1586038703595},{"_id":"themes/Daily/source/images/linkedIn.svg","hash":"18b3549b0447d605ca252fefcaa4d8e11179ce21","modified":1586660547754},{"_id":"themes/edinburgh/source/favicon/favicon.png","hash":"790e72ae1fc16ce1c33af13d19935ab6267eba38","modified":1586038703595},{"_id":"themes/edinburgh/source/images/drums.jpg","hash":"22d83aa1d06252e736d18a33017d88874c896010","modified":1587240255761},{"_id":"themes/edinburgh/source/images/emotiv.jpg","hash":"43cc364622a072c5e6946d1cd0c62b81ad663a1a","modified":1586037559171},{"_id":"themes/edinburgh/source/images/google.jpg","hash":"a15637dc5d91b3a33e546b13f0e045379e2c0518","modified":1587235698824},{"_id":"themes/edinburgh/source/images/ocr.jpg","hash":"76916e6d735fc34db34ff16d70976c4fbfd2e5a5","modified":1587239014722},{"_id":"themes/edinburgh/source/images/poetry.jpg","hash":"e6d09adaf05e87ee828d062a409fa58c06392852","modified":1587234465387},{"_id":"themes/edinburgh/source/images/bu3namigue.jpg","hash":"324ff5df8b9a5433870ca131ddccd986c01ee145","modified":1587235139705},{"_id":"themes/edinburgh/source/images/live-voice.jpg","hash":"4c8b5db7c5baf06d485d83454ea92afd309763e2","modified":1587235919463},{"_id":"themes/edinburgh/source/images/psychological.jpg","hash":"2621d7cd78fe6502f9fbd3ace86f32376707a33b","modified":1587239297454},{"_id":"themes/edinburgh/source/images/style-transfer.jpg","hash":"31fbfd435d87d99fbeea1ba5c7a3d9624517349a","modified":1587238669223},{"_id":"themes/edinburgh/source/images/automata.gif","hash":"83a4cc0247ae57fd14548057f978b608412a879b","modified":1586035296618},{"_id":"themes/edinburgh/source/images/jardin-sonoro.jpg","hash":"49674ab37fa4296e609d0075a9c59155a8309e8e","modified":1587239196086},{"_id":"themes/edinburgh/source/images/physarum.gif","hash":"dcb72f1a7a71c2682f86d0046a63adb2541ff158","modified":1587239683008},{"_id":"source/index.md","hash":"d254c1444679f63242cf8cdddf7bcfde02d7f2b2","modified":1587244604732},{"_id":"themes/edinburgh/source/images/transfer-style.jpg","hash":"31fbfd435d87d99fbeea1ba5c7a3d9624517349a","modified":1587238669223},{"_id":"themes/edinburgh/source/images/google.png","hash":"3ace6e1e53eadc8d1544cc549bf8643c9871fa7a","modified":1587239097320},{"_id":"themes/edinburgh/source/images/emotiv.png","hash":"d3f65a1fb7c496b5af2fb11721350749b77a43db","modified":1589078554078},{"_id":"themes/edinburgh/source/images/pattern2.jpg","hash":"8e1efeb75168b269ec02d5287f91143450c0fdc3","modified":1587240073492},{"_id":"source/_posts/Audio-Reactive-Slime/physarum.gif","hash":"dcb72f1a7a71c2682f86d0046a63adb2541ff158","modified":1587239683008}],"Category":[],"Data":[],"Page":[{"title":"about","_content":"\nI am a freelance software developer from Argentina specialized in Data Science and Creative Coding. I have a computer science degree and several years of experience as a programmer and math teacher.\n\nYou can check my resume and reviews at [codementor](https://www.codementor.io/mathiasgatti). Several tools and projects I develope are open source and available [here](https://github.com/mathigatti). In my spare time I contribute on open source projects like [FoxDot](https://github.com/Qirky/FoxDot/graphs/contributors), a real time music composition framework.\n\nI take part into [bu3nAmigue](https://www.instagram.com/bu3namigue/), an artistic collective that applies technology to the arts.\n\nYou can contact me through [Instagram](https://instagram.com/mathigatti), [facebook](https://facebook.com/mathi.gatti) or e-mail (mathigatti(a)gmail.com). I'm available for long-term mentoring, freelance jobs and interesting projects, you can hire me through [codementor](https://www.codementor.io/mathiasgatti).\n\n**Curriculum Vitae**\n- <a href=\"https://www.linkedin.com/in/mathias-gatti-a607945b/\">linkedIn</a>\n- <a href=\"https://www.codementor.io/mathiasgatti\">codementor</a>","source":"about/index.md","raw":"---\ntitle: about\n---\n\nI am a freelance software developer from Argentina specialized in Data Science and Creative Coding. I have a computer science degree and several years of experience as a programmer and math teacher.\n\nYou can check my resume and reviews at [codementor](https://www.codementor.io/mathiasgatti). Several tools and projects I develope are open source and available [here](https://github.com/mathigatti). In my spare time I contribute on open source projects like [FoxDot](https://github.com/Qirky/FoxDot/graphs/contributors), a real time music composition framework.\n\nI take part into [bu3nAmigue](https://www.instagram.com/bu3namigue/), an artistic collective that applies technology to the arts.\n\nYou can contact me through [Instagram](https://instagram.com/mathigatti), [facebook](https://facebook.com/mathi.gatti) or e-mail (mathigatti(a)gmail.com). I'm available for long-term mentoring, freelance jobs and interesting projects, you can hire me through [codementor](https://www.codementor.io/mathiasgatti).\n\n**Curriculum Vitae**\n- <a href=\"https://www.linkedin.com/in/mathias-gatti-a607945b/\">linkedIn</a>\n- <a href=\"https://www.codementor.io/mathiasgatti\">codementor</a>","date":"2020-04-18T21:19:02.270Z","updated":"2020-04-18T21:19:02.270Z","path":"about/index.html","_id":"ck8hfk5ch0000vrry173h9qte","comments":1,"layout":"page","content":"<p>I am a freelance software developer from Argentina specialized in Data Science and Creative Coding. I have a computer science degree and several years of experience as a programmer and math teacher.</p>\n<p>You can check my resume and reviews at <a href=\"https://www.codementor.io/mathiasgatti\" target=\"_blank\" rel=\"noopener\">codementor</a>. Several tools and projects I develope are open source and available <a href=\"https://github.com/mathigatti\" target=\"_blank\" rel=\"noopener\">here</a>. In my spare time I contribute on open source projects like <a href=\"https://github.com/Qirky/FoxDot/graphs/contributors\" target=\"_blank\" rel=\"noopener\">FoxDot</a>, a real time music composition framework.</p>\n<p>I take part into <a href=\"https://www.instagram.com/bu3namigue/\" target=\"_blank\" rel=\"noopener\">bu3nAmigue</a>, an artistic collective that applies technology to the arts.</p>\n<p>You can contact me through <a href=\"https://instagram.com/mathigatti\" target=\"_blank\" rel=\"noopener\">Instagram</a>, <a href=\"https://facebook.com/mathi.gatti\" target=\"_blank\" rel=\"noopener\">facebook</a> or e-mail (mathigatti(a)gmail.com). I’m available for long-term mentoring, freelance jobs and interesting projects, you can hire me through <a href=\"https://www.codementor.io/mathiasgatti\" target=\"_blank\" rel=\"noopener\">codementor</a>.</p>\n<p><strong>Curriculum Vitae</strong></p>\n<ul>\n<li><a href=\"https://www.linkedin.com/in/mathias-gatti-a607945b/\" target=\"_blank\" rel=\"noopener\">linkedIn</a></li>\n<li><a href=\"https://www.codementor.io/mathiasgatti\" target=\"_blank\" rel=\"noopener\">codementor</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>I am a freelance software developer from Argentina specialized in Data Science and Creative Coding. I have a computer science degree and several years of experience as a programmer and math teacher.</p>\n<p>You can check my resume and reviews at <a href=\"https://www.codementor.io/mathiasgatti\" target=\"_blank\" rel=\"noopener\">codementor</a>. Several tools and projects I develope are open source and available <a href=\"https://github.com/mathigatti\" target=\"_blank\" rel=\"noopener\">here</a>. In my spare time I contribute on open source projects like <a href=\"https://github.com/Qirky/FoxDot/graphs/contributors\" target=\"_blank\" rel=\"noopener\">FoxDot</a>, a real time music composition framework.</p>\n<p>I take part into <a href=\"https://www.instagram.com/bu3namigue/\" target=\"_blank\" rel=\"noopener\">bu3nAmigue</a>, an artistic collective that applies technology to the arts.</p>\n<p>You can contact me through <a href=\"https://instagram.com/mathigatti\" target=\"_blank\" rel=\"noopener\">Instagram</a>, <a href=\"https://facebook.com/mathi.gatti\" target=\"_blank\" rel=\"noopener\">facebook</a> or e-mail (mathigatti(a)gmail.com). I’m available for long-term mentoring, freelance jobs and interesting projects, you can hire me through <a href=\"https://www.codementor.io/mathiasgatti\" target=\"_blank\" rel=\"noopener\">codementor</a>.</p>\n<p><strong>Curriculum Vitae</strong></p>\n<ul>\n<li><a href=\"https://www.linkedin.com/in/mathias-gatti-a607945b/\" target=\"_blank\" rel=\"noopener\">linkedIn</a></li>\n<li><a href=\"https://www.codementor.io/mathiasgatti\" target=\"_blank\" rel=\"noopener\">codementor</a></li>\n</ul>\n"},{"title":"archives","date":"2020-04-01T14:32:53.000Z","_content":"","source":"archives/index.md","raw":"---\ntitle: archives\ndate: 2020-04-01 11:32:53\n---\n","updated":"2020-04-01T14:32:53.156Z","path":"archives/index.html","comments":1,"layout":"page","_id":"ck8hfk5ck0001vrry5wkoh5ez","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"reviews","_content":"This is a sample of reviews I received working as a freelance developer and teacher at [codementor](https://www.codementor.io/@mathiasgatti). You can recharge the website to see a new set of reviews.\n\n<iframe src=\"https://reviews.mathigatti.com/\" frameBorder=\"0\" scrolling=\"no\" width=\"100%\" height=\"1600px\"></iframe>\n","source":"reviews/index.md","raw":"---\ntitle: reviews\n---\nThis is a sample of reviews I received working as a freelance developer and teacher at [codementor](https://www.codementor.io/@mathiasgatti). You can recharge the website to see a new set of reviews.\n\n<iframe src=\"https://reviews.mathigatti.com/\" frameBorder=\"0\" scrolling=\"no\" width=\"100%\" height=\"1600px\"></iframe>\n","date":"2020-04-06T15:46:50.126Z","updated":"2020-04-06T15:46:50.126Z","path":"reviews/index.html","_id":"ck8jb761g0001nlrybnj1cuyu","comments":1,"layout":"page","content":"<p>This is a sample of reviews I received working as a freelance developer and teacher at <a href=\"https://www.codementor.io/@mathiasgatti\" target=\"_blank\" rel=\"noopener\">codementor</a>. You can recharge the website to see a new set of reviews.</p>\n<iframe src=\"https://reviews.mathigatti.com/\" frameBorder=\"0\" scrolling=\"no\" width=\"100%\" height=\"1600px\"></iframe>\n","site":{"data":{}},"excerpt":"","more":"<p>This is a sample of reviews I received working as a freelance developer and teacher at <a href=\"https://www.codementor.io/@mathiasgatti\" target=\"_blank\" rel=\"noopener\">codementor</a>. You can recharge the website to see a new set of reviews.</p>\n<iframe src=\"https://reviews.mathigatti.com/\" frameBorder=\"0\" scrolling=\"no\" width=\"100%\" height=\"1600px\"></iframe>\n"},{"_content":"function resizeIframe(obj) {\nobj.style.height = obj.contentWindow.document.documentElement.scrollHeight + 'px';\n}\n","source":"reviews/index/iframe_height.js","raw":"function resizeIframe(obj) {\nobj.style.height = obj.contentWindow.document.documentElement.scrollHeight + 'px';\n}\n","date":"2020-04-02T23:37:13.225Z","updated":"2020-04-02T23:37:13.225Z","path":"reviews/index/iframe_height.js","layout":"false","_id":"ck8jefa9l0000cgryenxehwwc","title":"","comments":1,"content":"function resizeIframe(obj) {\nobj.style.height = obj.contentWindow.document.documentElement.scrollHeight + 'px';\n}\n","site":{"data":{}},"excerpt":"","more":"function resizeIframe(obj) {\nobj.style.height = obj.contentWindow.document.documentElement.scrollHeight + 'px';\n}\n"}],"Post":[{"title":"Number to Image","date":"2019-06-07T16:55:34.000Z","cover_image":"images/pattern.png","_content":"\nIn the following [link](https://gist.github.com/mathigatti/439a0e81556f2698c7db4f41189d201f) you can find a script to convert any number into a 2 dimensional pattern. The details about the implementation are [here](https://www.codementor.io/@mathiasgatti/the-beauty-formula-identifying-interesting-patterns-automatically-based-on-aesthetic-metrics-basic-clustering-example-with-scikit-learn-xka5d6do8).\n\n<img src=\"pattern.png\" width=\"100%\" border=\"5\" />","source":"_posts/number2image.md","raw":"---\ntitle: Number to Image\ndate: 2019-06-07 13:55:34\ncover_image: images/pattern.png\n---\n\nIn the following [link](https://gist.github.com/mathigatti/439a0e81556f2698c7db4f41189d201f) you can find a script to convert any number into a 2 dimensional pattern. The details about the implementation are [here](https://www.codementor.io/@mathiasgatti/the-beauty-formula-identifying-interesting-patterns-automatically-based-on-aesthetic-metrics-basic-clustering-example-with-scikit-learn-xka5d6do8).\n\n<img src=\"pattern.png\" width=\"100%\" border=\"5\" />","slug":"number2image","published":1,"updated":"2020-04-18T20:06:35.788Z","_id":"ck8hi88zu000085ry9tkg2461","comments":1,"layout":"post","photos":[],"link":"","content":"<p>In the following <a href=\"https://gist.github.com/mathigatti/439a0e81556f2698c7db4f41189d201f\" target=\"_blank\" rel=\"noopener\">link</a> you can find a script to convert any number into a 2 dimensional pattern. The details about the implementation are <a href=\"https://www.codementor.io/@mathiasgatti/the-beauty-formula-identifying-interesting-patterns-automatically-based-on-aesthetic-metrics-basic-clustering-example-with-scikit-learn-xka5d6do8\" target=\"_blank\" rel=\"noopener\">here</a>.</p>\n<img src=\"pattern.png\" width=\"100%\" border=\"5\" />","site":{"data":{}},"excerpt":"","more":"<p>In the following <a href=\"https://gist.github.com/mathigatti/439a0e81556f2698c7db4f41189d201f\" target=\"_blank\" rel=\"noopener\">link</a> you can find a script to convert any number into a 2 dimensional pattern. The details about the implementation are <a href=\"https://www.codementor.io/@mathiasgatti/the-beauty-formula-identifying-interesting-patterns-automatically-based-on-aesthetic-metrics-basic-clustering-example-with-scikit-learn-xka5d6do8\" target=\"_blank\" rel=\"noopener\">here</a>.</p>\n<img src=\"pattern.png\" width=\"100%\" border=\"5\" />"},{"title":"Jardin Sonoro","date":"2019-01-03T03:00:00.000Z","cover_image":"images/jardin-sonoro.jpg","_content":"On March 2019 I worked on an interactive app which allows people to walk through museums and public parks and receive notifications with descriptions, audios and images when they are close to some relevant place. The first version was exhibited at the Jardin Botanico of Buenos Aires under the title of \"Jardin Sonoro\". You can check and donwload the app [here](https://play.google.com/store/apps/details?id=com.jardinsonoro.buenosaires).\n\n<img src=\"inicio.png\" width=\"30%\" height=\"50%\"/>\n<img src=\"load.png\" width=\"30%\" height=\"50%\" />\n<img src=\"player.png\" width=\"30%\" height=\"50%\" />","source":"_posts/jardin-sonoro.md","raw":"---\ntitle: Jardin Sonoro\ndate: 01/03/2019\ncover_image: images/jardin-sonoro.jpg\n---\nOn March 2019 I worked on an interactive app which allows people to walk through museums and public parks and receive notifications with descriptions, audios and images when they are close to some relevant place. The first version was exhibited at the Jardin Botanico of Buenos Aires under the title of \"Jardin Sonoro\". You can check and donwload the app [here](https://play.google.com/store/apps/details?id=com.jardinsonoro.buenosaires).\n\n<img src=\"inicio.png\" width=\"30%\" height=\"50%\"/>\n<img src=\"load.png\" width=\"30%\" height=\"50%\" />\n<img src=\"player.png\" width=\"30%\" height=\"50%\" />","slug":"jardin-sonoro","published":1,"updated":"2020-04-18T18:45:56.042Z","_id":"ck8hj4b4c00024zry4lyp1yut","comments":1,"layout":"post","photos":[],"link":"","content":"<p>On March 2019 I worked on an interactive app which allows people to walk through museums and public parks and receive notifications with descriptions, audios and images when they are close to some relevant place. The first version was exhibited at the Jardin Botanico of Buenos Aires under the title of “Jardin Sonoro”. You can check and donwload the app <a href=\"https://play.google.com/store/apps/details?id=com.jardinsonoro.buenosaires\" target=\"_blank\" rel=\"noopener\">here</a>.</p>\n<img src=\"inicio.png\" width=\"30%\" height=\"50%\"/>\n<img src=\"load.png\" width=\"30%\" height=\"50%\" />\n<img src=\"player.png\" width=\"30%\" height=\"50%\" />","site":{"data":{}},"excerpt":"","more":"<p>On March 2019 I worked on an interactive app which allows people to walk through museums and public parks and receive notifications with descriptions, audios and images when they are close to some relevant place. The first version was exhibited at the Jardin Botanico of Buenos Aires under the title of “Jardin Sonoro”. You can check and donwload the app <a href=\"https://play.google.com/store/apps/details?id=com.jardinsonoro.buenosaires\" target=\"_blank\" rel=\"noopener\">here</a>.</p>\n<img src=\"inicio.png\" width=\"30%\" height=\"50%\"/>\n<img src=\"load.png\" width=\"30%\" height=\"50%\" />\n<img src=\"player.png\" width=\"30%\" height=\"50%\" />"},{"title":"Singing Synthesis","date":"2019-05-05T16:17:02.000Z","cover_image":"images/live-voice.jpg","_content":"\nReal Time Singing Synthesizer project made from sinsy-NG. The idea was to generate vocal audio samples on real time easily for live coding performances. The code is [here](https://github.com/mathigatti/midi2voice).\n\n## Demo\n[Here](https://www.youtube.com/watch?v=wvbV75Tw_24) is a video demonstration using the program to synthesize samples and load them into the FoxDot live coding environment.\n\n<a href=\"https://www.youtube.com/watch?v=wvbV75Tw_24\" ><img src=\"https://i.ytimg.com/vi/wvbV75Tw_24/maxresdefault.jpg\" width=\"100%\" border=\"5\" /></a>","source":"_posts/Singing-Synthesis.md","raw":"---\ntitle: Singing Synthesis\ndate: 2019-05-05 13:17:02\ntags:\ncover_image: images/live-voice.jpg\n---\n\nReal Time Singing Synthesizer project made from sinsy-NG. The idea was to generate vocal audio samples on real time easily for live coding performances. The code is [here](https://github.com/mathigatti/midi2voice).\n\n## Demo\n[Here](https://www.youtube.com/watch?v=wvbV75Tw_24) is a video demonstration using the program to synthesize samples and load them into the FoxDot live coding environment.\n\n<a href=\"https://www.youtube.com/watch?v=wvbV75Tw_24\" ><img src=\"https://i.ytimg.com/vi/wvbV75Tw_24/maxresdefault.jpg\" width=\"100%\" border=\"5\" /></a>","slug":"Singing-Synthesis","published":1,"updated":"2020-04-18T20:07:22.093Z","_id":"ck8hj9igf00034zry2cyocuoy","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Real Time Singing Synthesizer project made from sinsy-NG. The idea was to generate vocal audio samples on real time easily for live coding performances. The code is <a href=\"https://github.com/mathigatti/midi2voice\" target=\"_blank\" rel=\"noopener\">here</a>.</p>\n<h2 id=\"Demo\"><a href=\"#Demo\" class=\"headerlink\" title=\"Demo\"></a>Demo</h2><p><a href=\"https://www.youtube.com/watch?v=wvbV75Tw_24\" target=\"_blank\" rel=\"noopener\">Here</a> is a video demonstration using the program to synthesize samples and load them into the FoxDot live coding environment.</p>\n<p><a href=\"https://www.youtube.com/watch?v=wvbV75Tw_24\" target=\"_blank\" rel=\"noopener\" ><img src=\"https://i.ytimg.com/vi/wvbV75Tw_24/maxresdefault.jpg\" width=\"100%\" border=\"5\" /></a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Real Time Singing Synthesizer project made from sinsy-NG. The idea was to generate vocal audio samples on real time easily for live coding performances. The code is <a href=\"https://github.com/mathigatti/midi2voice\" target=\"_blank\" rel=\"noopener\">here</a>.</p>\n<h2 id=\"Demo\"><a href=\"#Demo\" class=\"headerlink\" title=\"Demo\"></a>Demo</h2><p><a href=\"https://www.youtube.com/watch?v=wvbV75Tw_24\" target=\"_blank\" rel=\"noopener\">Here</a> is a video demonstration using the program to synthesize samples and load them into the FoxDot live coding environment.</p>\n<p><a href=\"https://www.youtube.com/watch?v=wvbV75Tw_24\" target=\"_blank\" rel=\"noopener\" ><img src=\"https://i.ytimg.com/vi/wvbV75Tw_24/maxresdefault.jpg\" width=\"100%\" border=\"5\" /></a></p>\n"},{"title":"Audio Reactive Slime","date":"2019-12-31T14:06:33.000Z","cover_image":"images/physarum.gif","_content":"\nA slime mold simulation made by nicoptere and modified by [solquemal](https://solquemal.com) and me for audio reactivity. **Run the interactive demo [here](https://physarum.mathigatti.com/).** It works better on Firefox.\n\nInspired by this [amazing work](https://www.sagejenson.com/physarum). Implemented from [this paper](http://eprints.uwe.ac.uk/15260/1/artl.2010.16.2.pdf)\n\nYou can check a sample of this [here](https://www.instagram.com/p/B6ytj5rlUMf/?utm_source=ig_web_copy_link).\n\n\n<a href=\"https://physarum.mathigatti.com/\"><img src=\"physarum.gif\" width=\"100%\" border=\"5\" /></a>","source":"_posts/Audio-Reactive-Slime.md","raw":"---\ntitle: Audio Reactive Slime\ndate: 2019-12-31 11:06:33\ntags:\ncover_image: images/physarum.gif\n---\n\nA slime mold simulation made by nicoptere and modified by [solquemal](https://solquemal.com) and me for audio reactivity. **Run the interactive demo [here](https://physarum.mathigatti.com/).** It works better on Firefox.\n\nInspired by this [amazing work](https://www.sagejenson.com/physarum). Implemented from [this paper](http://eprints.uwe.ac.uk/15260/1/artl.2010.16.2.pdf)\n\nYou can check a sample of this [here](https://www.instagram.com/p/B6ytj5rlUMf/?utm_source=ig_web_copy_link).\n\n\n<a href=\"https://physarum.mathigatti.com/\"><img src=\"physarum.gif\" width=\"100%\" border=\"5\" /></a>","slug":"Audio-Reactive-Slime","published":1,"updated":"2020-04-18T20:20:13.752Z","_id":"ck8jb761d0000nlry8cv13tw7","comments":1,"layout":"post","photos":[],"link":"","content":"<p>A slime mold simulation made by nicoptere and modified by <a href=\"https://solquemal.com\" target=\"_blank\" rel=\"noopener\">solquemal</a> and me for audio reactivity. <strong>Run the interactive demo <a href=\"https://physarum.mathigatti.com/\" target=\"_blank\" rel=\"noopener\">here</a>.</strong> It works better on Firefox.</p>\n<p>Inspired by this <a href=\"https://www.sagejenson.com/physarum\" target=\"_blank\" rel=\"noopener\">amazing work</a>. Implemented from <a href=\"http://eprints.uwe.ac.uk/15260/1/artl.2010.16.2.pdf\" target=\"_blank\" rel=\"noopener\">this paper</a></p>\n<p>You can check a sample of this <a href=\"https://www.instagram.com/p/B6ytj5rlUMf/?utm_source=ig_web_copy_link\" target=\"_blank\" rel=\"noopener\">here</a>.</p>\n<p><a href=\"https://physarum.mathigatti.com/\" target=\"_blank\" rel=\"noopener\"><img src=\"physarum.gif\" width=\"100%\" border=\"5\" /></a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>A slime mold simulation made by nicoptere and modified by <a href=\"https://solquemal.com\" target=\"_blank\" rel=\"noopener\">solquemal</a> and me for audio reactivity. <strong>Run the interactive demo <a href=\"https://physarum.mathigatti.com/\" target=\"_blank\" rel=\"noopener\">here</a>.</strong> It works better on Firefox.</p>\n<p>Inspired by this <a href=\"https://www.sagejenson.com/physarum\" target=\"_blank\" rel=\"noopener\">amazing work</a>. Implemented from <a href=\"http://eprints.uwe.ac.uk/15260/1/artl.2010.16.2.pdf\" target=\"_blank\" rel=\"noopener\">this paper</a></p>\n<p>You can check a sample of this <a href=\"https://www.instagram.com/p/B6ytj5rlUMf/?utm_source=ig_web_copy_link\" target=\"_blank\" rel=\"noopener\">here</a>.</p>\n<p><a href=\"https://physarum.mathigatti.com/\" target=\"_blank\" rel=\"noopener\"><img src=\"physarum.gif\" width=\"100%\" border=\"5\" /></a></p>\n"},{"title":"AI Poetry","date":"2020-01-21T14:10:27.000Z","cover_image":"images/poetry.jpg","_content":"\nPlaying around generating new texts using artificial intelligence algorithms (GPT-2 model) that are inspired on [beachslang](https://en.wikipedia.org/wiki/Beach_Slang) lyrics and spanish whatsapp conversations.\n\n# Beachslang\n\n## Weed of the Wild\n\n\tDid You Know?\n\tWeeds are born\n\tThey are born with rage\n\tThey are born with lust\n\tThey are born with lust\n\tThey\n\n## Cut to a town full of young men and a dying city full of dying punks\n\n\tThere's a time to breathe\n\tThere's a time to run\n\tThere's a time to punch\n\tThere's a time to die\n\n\tCut to a drunk jock with a face full of trash\n\tAll these things are lies\n\tAll these things are lies\n\n\tThere's a time to cry\n\tThere's a time to shine\n\tThere's a time to bleed\n\n\tWe're not dumb\n\tWe're not numb\n\tThis town is fucked\n\tWe are wired to fight\n\tWe are wired to die\n\n## Baba o\n\n\tI'm a punk\n\tI'm a punk\n\tI'm a punk\n\tI'm a punk\n\tI'm a punk\n\n\tI'm a punk\n\tI'm a punk\n\tI'm a punk\n\tI'm a punk\n\tI'm a punk\n\n\tI'm a punk\n\tI'm a punk\n\tI'm a punk\n\tI'm a punk\n\tI'm a punk\n\n# Whatsapp\n\n## Sample 1\n\n\tVos me dejaste re jugante\n\ten un barrio muy al punto medio.\n\tEse look tan cool, me gusta.\n\tCapaz puedas hoy, ojalá\n\thoy a la carta.\n\n## Sample 2\n\n\tCapaz este momento es súbito,\n\tes súbito y tu casa.\n\tTe volvés una especie de movida.\n\tCapaz para llegar a alguien,\n\tpara haberte con alguien todo el rato,\n\tcapaz es un poco tipo venir de la nube con vos.\n\n## Sample 3\n\n\tEstaba todo re infierno y muy extracurriculares\n\tme parecía que me había que hacer programación\n\ttipo apellido de ese plan\n\tel final es una vaca\n\tbueno, quizás es una vaca - ya fue\n\ttodo sirve para nacer.","source":"_posts/AI-Poem-Writer.md","raw":"---\ntitle: AI Poetry\ndate: 2020-01-21 11:10:27\ntags: poetry, gpt-2\ncover_image: images/poetry.jpg\n---\n\nPlaying around generating new texts using artificial intelligence algorithms (GPT-2 model) that are inspired on [beachslang](https://en.wikipedia.org/wiki/Beach_Slang) lyrics and spanish whatsapp conversations.\n\n# Beachslang\n\n## Weed of the Wild\n\n\tDid You Know?\n\tWeeds are born\n\tThey are born with rage\n\tThey are born with lust\n\tThey are born with lust\n\tThey\n\n## Cut to a town full of young men and a dying city full of dying punks\n\n\tThere's a time to breathe\n\tThere's a time to run\n\tThere's a time to punch\n\tThere's a time to die\n\n\tCut to a drunk jock with a face full of trash\n\tAll these things are lies\n\tAll these things are lies\n\n\tThere's a time to cry\n\tThere's a time to shine\n\tThere's a time to bleed\n\n\tWe're not dumb\n\tWe're not numb\n\tThis town is fucked\n\tWe are wired to fight\n\tWe are wired to die\n\n## Baba o\n\n\tI'm a punk\n\tI'm a punk\n\tI'm a punk\n\tI'm a punk\n\tI'm a punk\n\n\tI'm a punk\n\tI'm a punk\n\tI'm a punk\n\tI'm a punk\n\tI'm a punk\n\n\tI'm a punk\n\tI'm a punk\n\tI'm a punk\n\tI'm a punk\n\tI'm a punk\n\n# Whatsapp\n\n## Sample 1\n\n\tVos me dejaste re jugante\n\ten un barrio muy al punto medio.\n\tEse look tan cool, me gusta.\n\tCapaz puedas hoy, ojalá\n\thoy a la carta.\n\n## Sample 2\n\n\tCapaz este momento es súbito,\n\tes súbito y tu casa.\n\tTe volvés una especie de movida.\n\tCapaz para llegar a alguien,\n\tpara haberte con alguien todo el rato,\n\tcapaz es un poco tipo venir de la nube con vos.\n\n## Sample 3\n\n\tEstaba todo re infierno y muy extracurriculares\n\tme parecía que me había que hacer programación\n\ttipo apellido de ese plan\n\tel final es una vaca\n\tbueno, quizás es una vaca - ya fue\n\ttodo sirve para nacer.","slug":"AI-Poem-Writer","published":1,"updated":"2020-04-18T19:03:02.660Z","_id":"ck8jb761h0002nlryden35kvr","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Playing around generating new texts using artificial intelligence algorithms (GPT-2 model) that are inspired on <a href=\"https://en.wikipedia.org/wiki/Beach_Slang\" target=\"_blank\" rel=\"noopener\">beachslang</a> lyrics and spanish whatsapp conversations.</p>\n<h1 id=\"Beachslang\"><a href=\"#Beachslang\" class=\"headerlink\" title=\"Beachslang\"></a>Beachslang</h1><h2 id=\"Weed-of-the-Wild\"><a href=\"#Weed-of-the-Wild\" class=\"headerlink\" title=\"Weed of the Wild\"></a>Weed of the Wild</h2><pre><code>Did You Know?\nWeeds are born\nThey are born with rage\nThey are born with lust\nThey are born with lust\nThey</code></pre><h2 id=\"Cut-to-a-town-full-of-young-men-and-a-dying-city-full-of-dying-punks\"><a href=\"#Cut-to-a-town-full-of-young-men-and-a-dying-city-full-of-dying-punks\" class=\"headerlink\" title=\"Cut to a town full of young men and a dying city full of dying punks\"></a>Cut to a town full of young men and a dying city full of dying punks</h2><pre><code>There&apos;s a time to breathe\nThere&apos;s a time to run\nThere&apos;s a time to punch\nThere&apos;s a time to die\n\nCut to a drunk jock with a face full of trash\nAll these things are lies\nAll these things are lies\n\nThere&apos;s a time to cry\nThere&apos;s a time to shine\nThere&apos;s a time to bleed\n\nWe&apos;re not dumb\nWe&apos;re not numb\nThis town is fucked\nWe are wired to fight\nWe are wired to die</code></pre><h2 id=\"Baba-o\"><a href=\"#Baba-o\" class=\"headerlink\" title=\"Baba o\"></a>Baba o</h2><pre><code>I&apos;m a punk\nI&apos;m a punk\nI&apos;m a punk\nI&apos;m a punk\nI&apos;m a punk\n\nI&apos;m a punk\nI&apos;m a punk\nI&apos;m a punk\nI&apos;m a punk\nI&apos;m a punk\n\nI&apos;m a punk\nI&apos;m a punk\nI&apos;m a punk\nI&apos;m a punk\nI&apos;m a punk</code></pre><h1 id=\"Whatsapp\"><a href=\"#Whatsapp\" class=\"headerlink\" title=\"Whatsapp\"></a>Whatsapp</h1><h2 id=\"Sample-1\"><a href=\"#Sample-1\" class=\"headerlink\" title=\"Sample 1\"></a>Sample 1</h2><pre><code>Vos me dejaste re jugante\nen un barrio muy al punto medio.\nEse look tan cool, me gusta.\nCapaz puedas hoy, ojalá\nhoy a la carta.</code></pre><h2 id=\"Sample-2\"><a href=\"#Sample-2\" class=\"headerlink\" title=\"Sample 2\"></a>Sample 2</h2><pre><code>Capaz este momento es súbito,\nes súbito y tu casa.\nTe volvés una especie de movida.\nCapaz para llegar a alguien,\npara haberte con alguien todo el rato,\ncapaz es un poco tipo venir de la nube con vos.</code></pre><h2 id=\"Sample-3\"><a href=\"#Sample-3\" class=\"headerlink\" title=\"Sample 3\"></a>Sample 3</h2><pre><code>Estaba todo re infierno y muy extracurriculares\nme parecía que me había que hacer programación\ntipo apellido de ese plan\nel final es una vaca\nbueno, quizás es una vaca - ya fue\ntodo sirve para nacer.</code></pre>","site":{"data":{}},"excerpt":"","more":"<p>Playing around generating new texts using artificial intelligence algorithms (GPT-2 model) that are inspired on <a href=\"https://en.wikipedia.org/wiki/Beach_Slang\" target=\"_blank\" rel=\"noopener\">beachslang</a> lyrics and spanish whatsapp conversations.</p>\n<h1 id=\"Beachslang\"><a href=\"#Beachslang\" class=\"headerlink\" title=\"Beachslang\"></a>Beachslang</h1><h2 id=\"Weed-of-the-Wild\"><a href=\"#Weed-of-the-Wild\" class=\"headerlink\" title=\"Weed of the Wild\"></a>Weed of the Wild</h2><pre><code>Did You Know?\nWeeds are born\nThey are born with rage\nThey are born with lust\nThey are born with lust\nThey</code></pre><h2 id=\"Cut-to-a-town-full-of-young-men-and-a-dying-city-full-of-dying-punks\"><a href=\"#Cut-to-a-town-full-of-young-men-and-a-dying-city-full-of-dying-punks\" class=\"headerlink\" title=\"Cut to a town full of young men and a dying city full of dying punks\"></a>Cut to a town full of young men and a dying city full of dying punks</h2><pre><code>There&apos;s a time to breathe\nThere&apos;s a time to run\nThere&apos;s a time to punch\nThere&apos;s a time to die\n\nCut to a drunk jock with a face full of trash\nAll these things are lies\nAll these things are lies\n\nThere&apos;s a time to cry\nThere&apos;s a time to shine\nThere&apos;s a time to bleed\n\nWe&apos;re not dumb\nWe&apos;re not numb\nThis town is fucked\nWe are wired to fight\nWe are wired to die</code></pre><h2 id=\"Baba-o\"><a href=\"#Baba-o\" class=\"headerlink\" title=\"Baba o\"></a>Baba o</h2><pre><code>I&apos;m a punk\nI&apos;m a punk\nI&apos;m a punk\nI&apos;m a punk\nI&apos;m a punk\n\nI&apos;m a punk\nI&apos;m a punk\nI&apos;m a punk\nI&apos;m a punk\nI&apos;m a punk\n\nI&apos;m a punk\nI&apos;m a punk\nI&apos;m a punk\nI&apos;m a punk\nI&apos;m a punk</code></pre><h1 id=\"Whatsapp\"><a href=\"#Whatsapp\" class=\"headerlink\" title=\"Whatsapp\"></a>Whatsapp</h1><h2 id=\"Sample-1\"><a href=\"#Sample-1\" class=\"headerlink\" title=\"Sample 1\"></a>Sample 1</h2><pre><code>Vos me dejaste re jugante\nen un barrio muy al punto medio.\nEse look tan cool, me gusta.\nCapaz puedas hoy, ojalá\nhoy a la carta.</code></pre><h2 id=\"Sample-2\"><a href=\"#Sample-2\" class=\"headerlink\" title=\"Sample 2\"></a>Sample 2</h2><pre><code>Capaz este momento es súbito,\nes súbito y tu casa.\nTe volvés una especie de movida.\nCapaz para llegar a alguien,\npara haberte con alguien todo el rato,\ncapaz es un poco tipo venir de la nube con vos.</code></pre><h2 id=\"Sample-3\"><a href=\"#Sample-3\" class=\"headerlink\" title=\"Sample 3\"></a>Sample 3</h2><pre><code>Estaba todo re infierno y muy extracurriculares\nme parecía que me había que hacer programación\ntipo apellido de ese plan\nel final es una vaca\nbueno, quizás es una vaca - ya fue\ntodo sirve para nacer.</code></pre>"},{"title":"Midi to Voice","date":"2018-06-10T14:09:07.000Z","cover_image":"images/shallow.jpg","_content":"\nUsing the HMM-based Singing Voice Synthesis System from the Nagoya Institute of Technology I implented a [program](https://github.com/mathigatti/midi2voice) to convert music sheets in midi file format into voices that sing the specified notes. [Here](https://soundcloud.com/mathias-gatti/shallow-midi2voice) you can find a sample cover of Lady Gaga - Shallow.\n\n<a href=\"https://soundcloud.com/mathias-gatti/shallow-midi2voice\"><img src=\"shallow.jpg\" width=\"50%\" height=\"50%\"/></a>","source":"_posts/Midi-to-Voice.md","raw":"---\ntitle: Midi to Voice\ndate: 2018-06-10 11:09:07\ntags:\ncover_image: images/shallow.jpg\n---\n\nUsing the HMM-based Singing Voice Synthesis System from the Nagoya Institute of Technology I implented a [program](https://github.com/mathigatti/midi2voice) to convert music sheets in midi file format into voices that sing the specified notes. [Here](https://soundcloud.com/mathias-gatti/shallow-midi2voice) you can find a sample cover of Lady Gaga - Shallow.\n\n<a href=\"https://soundcloud.com/mathias-gatti/shallow-midi2voice\"><img src=\"shallow.jpg\" width=\"50%\" height=\"50%\"/></a>","slug":"Midi-to-Voice","published":1,"updated":"2020-04-18T18:48:02.319Z","_id":"ck8jb761i0003nlrybwo7gr1d","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Using the HMM-based Singing Voice Synthesis System from the Nagoya Institute of Technology I implented a <a href=\"https://github.com/mathigatti/midi2voice\" target=\"_blank\" rel=\"noopener\">program</a> to convert music sheets in midi file format into voices that sing the specified notes. <a href=\"https://soundcloud.com/mathias-gatti/shallow-midi2voice\" target=\"_blank\" rel=\"noopener\">Here</a> you can find a sample cover of Lady Gaga - Shallow.</p>\n<p><a href=\"https://soundcloud.com/mathias-gatti/shallow-midi2voice\" target=\"_blank\" rel=\"noopener\"><img src=\"shallow.jpg\" width=\"50%\" height=\"50%\"/></a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Using the HMM-based Singing Voice Synthesis System from the Nagoya Institute of Technology I implented a <a href=\"https://github.com/mathigatti/midi2voice\" target=\"_blank\" rel=\"noopener\">program</a> to convert music sheets in midi file format into voices that sing the specified notes. <a href=\"https://soundcloud.com/mathias-gatti/shallow-midi2voice\" target=\"_blank\" rel=\"noopener\">Here</a> you can find a sample cover of Lady Gaga - Shallow.</p>\n<p><a href=\"https://soundcloud.com/mathias-gatti/shallow-midi2voice\" target=\"_blank\" rel=\"noopener\"><img src=\"shallow.jpg\" width=\"50%\" height=\"50%\"/></a></p>\n"},{"title":"Normalized Google Distance","date":"2019-06-09T16:27:42.000Z","summary":"Measuring how similar are two words by scraping Google results.","_content":"\nBased on the count of google results we can infer the popularity of a word. Also the relationship between the frequency of two words together with respect to its individual frequency is a useful measure of how much two words are related.\n\n<img src=\"https://ucarecdn.com/f8821813-5740-4332-ba60-2f5c474464f6/\" width=\"100%\" border=\"5\" />\n\nBased on these ideas is defined the [Normalized Google distance](https://en.wikipedia.org/wiki/Normalized_Google_distance), in [this](https://www.codementor.io/@mathiasgatti/python-implementation-of-normalized-google-distance-simple-web-scraping-example-vrwwu5w58) post I show how to implement it in python using basic web scraping tools. The final code can be found [here](https://gist.github.com/mathigatti/aa12d484ad545e909e48bfa080a11eae).","source":"_posts/Normalized-Google-Distance.md","raw":"---\ntitle: Normalized Google Distance\ndate: 2019-06-09 13:27:42\ntags:\nsummary: Measuring how similar are two words by scraping Google results.\n---\n\nBased on the count of google results we can infer the popularity of a word. Also the relationship between the frequency of two words together with respect to its individual frequency is a useful measure of how much two words are related.\n\n<img src=\"https://ucarecdn.com/f8821813-5740-4332-ba60-2f5c474464f6/\" width=\"100%\" border=\"5\" />\n\nBased on these ideas is defined the [Normalized Google distance](https://en.wikipedia.org/wiki/Normalized_Google_distance), in [this](https://www.codementor.io/@mathiasgatti/python-implementation-of-normalized-google-distance-simple-web-scraping-example-vrwwu5w58) post I show how to implement it in python using basic web scraping tools. The final code can be found [here](https://gist.github.com/mathigatti/aa12d484ad545e909e48bfa080a11eae).","slug":"Normalized-Google-Distance","published":1,"updated":"2020-05-10T01:22:23.841Z","_id":"ck8jb761j0004nlry05je9wjk","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Based on the count of google results we can infer the popularity of a word. Also the relationship between the frequency of two words together with respect to its individual frequency is a useful measure of how much two words are related.</p>\n<img src=\"https://ucarecdn.com/f8821813-5740-4332-ba60-2f5c474464f6/\" width=\"100%\" border=\"5\" />\n\n<p>Based on these ideas is defined the <a href=\"https://en.wikipedia.org/wiki/Normalized_Google_distance\" target=\"_blank\" rel=\"noopener\">Normalized Google distance</a>, in <a href=\"https://www.codementor.io/@mathiasgatti/python-implementation-of-normalized-google-distance-simple-web-scraping-example-vrwwu5w58\" target=\"_blank\" rel=\"noopener\">this</a> post I show how to implement it in python using basic web scraping tools. The final code can be found <a href=\"https://gist.github.com/mathigatti/aa12d484ad545e909e48bfa080a11eae\" target=\"_blank\" rel=\"noopener\">here</a>.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Based on the count of google results we can infer the popularity of a word. Also the relationship between the frequency of two words together with respect to its individual frequency is a useful measure of how much two words are related.</p>\n<img src=\"https://ucarecdn.com/f8821813-5740-4332-ba60-2f5c474464f6/\" width=\"100%\" border=\"5\" />\n\n<p>Based on these ideas is defined the <a href=\"https://en.wikipedia.org/wiki/Normalized_Google_distance\" target=\"_blank\" rel=\"noopener\">Normalized Google distance</a>, in <a href=\"https://www.codementor.io/@mathiasgatti/python-implementation-of-normalized-google-distance-simple-web-scraping-example-vrwwu5w58\" target=\"_blank\" rel=\"noopener\">this</a> post I show how to implement it in python using basic web scraping tools. The final code can be found <a href=\"https://gist.github.com/mathigatti/aa12d484ad545e909e48bfa080a11eae\" target=\"_blank\" rel=\"noopener\">here</a>.</p>\n"},{"title":"Regenerative cellular automata","date":"2020-03-24T16:55:34.000Z","cover_image":"images/automata.gif","_content":"\nTesting neural networks able to find cellular automata rules with regenerative capabilities.\n\n<img src=\"automata1.gif\">\n<img src=\"automata2.gif\">\n\nWork inspired on the amazing work of [Mordvintsev, et al.](https://distill.pub/2020/growing-ca/).\n\n\n","source":"_posts/Regenerative-cellular-automata.md","raw":"---\ntitle: Regenerative cellular automata\ndate: 2020-03-24 13:55:34\ntags:\ncover_image: images/automata.gif\n---\n\nTesting neural networks able to find cellular automata rules with regenerative capabilities.\n\n<img src=\"automata1.gif\">\n<img src=\"automata2.gif\">\n\nWork inspired on the amazing work of [Mordvintsev, et al.](https://distill.pub/2020/growing-ca/).\n\n\n","slug":"Regenerative-cellular-automata","published":1,"updated":"2020-05-10T01:06:22.362Z","_id":"ck8jb761k0005nlry965w6k6l","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Testing neural networks able to find cellular automata rules with regenerative capabilities.</p>\n<img src=\"automata1.gif\">\n<img src=\"automata2.gif\">\n\n<p>Work inspired on the amazing work of <a href=\"https://distill.pub/2020/growing-ca/\" target=\"_blank\" rel=\"noopener\">Mordvintsev, et al.</a>.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Testing neural networks able to find cellular automata rules with regenerative capabilities.</p>\n<img src=\"automata1.gif\">\n<img src=\"automata2.gif\">\n\n<p>Work inspired on the amazing work of <a href=\"https://distill.pub/2020/growing-ca/\" target=\"_blank\" rel=\"noopener\">Mordvintsev, et al.</a>.</p>\n"},{"title":"Scraping formatted text from images","date":"2019-10-03T16:28:21.000Z","summary":"The goal of this project is to provide a way to postprocess OCR text from tables or formatted text images into something more maneagable, so it's more appropiate for text processing tasks like extracting full lines of text or filtering words.","_content":"\n# Image to Text conversion utilities\n\nYou can find [here](https://github.com/mathigatti/img2txt) a small tokenization utility and examples of table extraction from images using Google Vision API. Google provides a good OCR to extract text from images but the output is not the best sometimes, in this repository I provide a simple postprocessing of the output in order to make it easier to use the API output.\n\n## Motivation\n\nGoogle OCR provides a text output which might not have the expected format, if that's the case it also provides a JSON output with information about the position of each recognized entity. The problem is that this data is not so well structured for some tasks, extracting tokens (Series of characters without spaces between each other) is not so easy with this JSON since it doesn't provides directly this information. The goal of this is to provide a way to postprocess this data into something more maneagable, so it's more appropiate for text processing tasks like extracting full lines of text or filtering words.\n\nIn order to do this a postprocessing code is provided at `src/image2tokens.py`. This is applied in order to extract tokens and then even more abstract concepts like text lines or table columns.\n\n## Demo\n\n### Sample Input\n\n<img src=\"https://github.com/mathigatti/img2txt/blob/master/sample/input/sample.png?raw=true\" width=\"100%\" border=\"5\" />\n\n### Sample Output\n```\n                          HR Information                                 Contact\n                                Position                                  Salary                                  Office                                   Extn.\n                              Accountant                                $162,700                                   Tokyo                                    5407\n           Chief Executive Officer (CEO)                              $1,200,000                                  London                                    5797\n                 Junior Technical Author                                 $86,000                           San Francisco                                    1562\n                       Software Engineer                                $132,000                                  London                                    2558\n                       Software Engineer                                $206,850                           San Francisco                                    1314\n                  Integration Specialist                                $372,000                                New York                                    4804\n                       Software Engineer                                $163,500                                  London                                    6222\n                       Pre-Sales Support                                $106,450                                New York                                    8330\n                         Sales Assistant                                $145,600                                New York                                    3990\n             Senior Javascript Developer                                $433,060                               Edinburgh                                    6224\n```","source":"_posts/Scraping-formatted-text-from-images.md","raw":"---\ntitle: Scraping formatted text from images\ndate: 2019-10-03 13:28:21\ntags: ocr\nsummary: The goal of this project is to provide a way to postprocess OCR text from tables or formatted text images into something more maneagable, so it's more appropiate for text processing tasks like extracting full lines of text or filtering words.\n---\n\n# Image to Text conversion utilities\n\nYou can find [here](https://github.com/mathigatti/img2txt) a small tokenization utility and examples of table extraction from images using Google Vision API. Google provides a good OCR to extract text from images but the output is not the best sometimes, in this repository I provide a simple postprocessing of the output in order to make it easier to use the API output.\n\n## Motivation\n\nGoogle OCR provides a text output which might not have the expected format, if that's the case it also provides a JSON output with information about the position of each recognized entity. The problem is that this data is not so well structured for some tasks, extracting tokens (Series of characters without spaces between each other) is not so easy with this JSON since it doesn't provides directly this information. The goal of this is to provide a way to postprocess this data into something more maneagable, so it's more appropiate for text processing tasks like extracting full lines of text or filtering words.\n\nIn order to do this a postprocessing code is provided at `src/image2tokens.py`. This is applied in order to extract tokens and then even more abstract concepts like text lines or table columns.\n\n## Demo\n\n### Sample Input\n\n<img src=\"https://github.com/mathigatti/img2txt/blob/master/sample/input/sample.png?raw=true\" width=\"100%\" border=\"5\" />\n\n### Sample Output\n```\n                          HR Information                                 Contact\n                                Position                                  Salary                                  Office                                   Extn.\n                              Accountant                                $162,700                                   Tokyo                                    5407\n           Chief Executive Officer (CEO)                              $1,200,000                                  London                                    5797\n                 Junior Technical Author                                 $86,000                           San Francisco                                    1562\n                       Software Engineer                                $132,000                                  London                                    2558\n                       Software Engineer                                $206,850                           San Francisco                                    1314\n                  Integration Specialist                                $372,000                                New York                                    4804\n                       Software Engineer                                $163,500                                  London                                    6222\n                       Pre-Sales Support                                $106,450                                New York                                    8330\n                         Sales Assistant                                $145,600                                New York                                    3990\n             Senior Javascript Developer                                $433,060                               Edinburgh                                    6224\n```","slug":"Scraping-formatted-text-from-images","published":1,"updated":"2020-05-10T02:50:35.326Z","_id":"ck8jb761l0006nlryb17b2n5h","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"Image-to-Text-conversion-utilities\"><a href=\"#Image-to-Text-conversion-utilities\" class=\"headerlink\" title=\"Image to Text conversion utilities\"></a>Image to Text conversion utilities</h1><p>You can find <a href=\"https://github.com/mathigatti/img2txt\" target=\"_blank\" rel=\"noopener\">here</a> a small tokenization utility and examples of table extraction from images using Google Vision API. Google provides a good OCR to extract text from images but the output is not the best sometimes, in this repository I provide a simple postprocessing of the output in order to make it easier to use the API output.</p>\n<h2 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h2><p>Google OCR provides a text output which might not have the expected format, if that’s the case it also provides a JSON output with information about the position of each recognized entity. The problem is that this data is not so well structured for some tasks, extracting tokens (Series of characters without spaces between each other) is not so easy with this JSON since it doesn’t provides directly this information. The goal of this is to provide a way to postprocess this data into something more maneagable, so it’s more appropiate for text processing tasks like extracting full lines of text or filtering words.</p>\n<p>In order to do this a postprocessing code is provided at <code>src/image2tokens.py</code>. This is applied in order to extract tokens and then even more abstract concepts like text lines or table columns.</p>\n<h2 id=\"Demo\"><a href=\"#Demo\" class=\"headerlink\" title=\"Demo\"></a>Demo</h2><h3 id=\"Sample-Input\"><a href=\"#Sample-Input\" class=\"headerlink\" title=\"Sample Input\"></a>Sample Input</h3><img src=\"https://github.com/mathigatti/img2txt/blob/master/sample/input/sample.png?raw=true\" width=\"100%\" border=\"5\" />\n\n<h3 id=\"Sample-Output\"><a href=\"#Sample-Output\" class=\"headerlink\" title=\"Sample Output\"></a>Sample Output</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">               HR Information                                 Contact</span><br><span class=\"line\">                     Position                                  Salary                                  Office                                   Extn.</span><br><span class=\"line\">                   Accountant                                $162,700                                   Tokyo                                    5407</span><br><span class=\"line\">Chief Executive Officer (CEO)                              $1,200,000                                  London                                    5797</span><br><span class=\"line\">      Junior Technical Author                                 $86,000                           San Francisco                                    1562</span><br><span class=\"line\">            Software Engineer                                $132,000                                  London                                    2558</span><br><span class=\"line\">            Software Engineer                                $206,850                           San Francisco                                    1314</span><br><span class=\"line\">       Integration Specialist                                $372,000                                New York                                    4804</span><br><span class=\"line\">            Software Engineer                                $163,500                                  London                                    6222</span><br><span class=\"line\">            Pre-Sales Support                                $106,450                                New York                                    8330</span><br><span class=\"line\">              Sales Assistant                                $145,600                                New York                                    3990</span><br><span class=\"line\">  Senior Javascript Developer                                $433,060                               Edinburgh                                    6224</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Image-to-Text-conversion-utilities\"><a href=\"#Image-to-Text-conversion-utilities\" class=\"headerlink\" title=\"Image to Text conversion utilities\"></a>Image to Text conversion utilities</h1><p>You can find <a href=\"https://github.com/mathigatti/img2txt\" target=\"_blank\" rel=\"noopener\">here</a> a small tokenization utility and examples of table extraction from images using Google Vision API. Google provides a good OCR to extract text from images but the output is not the best sometimes, in this repository I provide a simple postprocessing of the output in order to make it easier to use the API output.</p>\n<h2 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h2><p>Google OCR provides a text output which might not have the expected format, if that’s the case it also provides a JSON output with information about the position of each recognized entity. The problem is that this data is not so well structured for some tasks, extracting tokens (Series of characters without spaces between each other) is not so easy with this JSON since it doesn’t provides directly this information. The goal of this is to provide a way to postprocess this data into something more maneagable, so it’s more appropiate for text processing tasks like extracting full lines of text or filtering words.</p>\n<p>In order to do this a postprocessing code is provided at <code>src/image2tokens.py</code>. This is applied in order to extract tokens and then even more abstract concepts like text lines or table columns.</p>\n<h2 id=\"Demo\"><a href=\"#Demo\" class=\"headerlink\" title=\"Demo\"></a>Demo</h2><h3 id=\"Sample-Input\"><a href=\"#Sample-Input\" class=\"headerlink\" title=\"Sample Input\"></a>Sample Input</h3><img src=\"https://github.com/mathigatti/img2txt/blob/master/sample/input/sample.png?raw=true\" width=\"100%\" border=\"5\" />\n\n<h3 id=\"Sample-Output\"><a href=\"#Sample-Output\" class=\"headerlink\" title=\"Sample Output\"></a>Sample Output</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">               HR Information                                 Contact</span><br><span class=\"line\">                     Position                                  Salary                                  Office                                   Extn.</span><br><span class=\"line\">                   Accountant                                $162,700                                   Tokyo                                    5407</span><br><span class=\"line\">Chief Executive Officer (CEO)                              $1,200,000                                  London                                    5797</span><br><span class=\"line\">      Junior Technical Author                                 $86,000                           San Francisco                                    1562</span><br><span class=\"line\">            Software Engineer                                $132,000                                  London                                    2558</span><br><span class=\"line\">            Software Engineer                                $206,850                           San Francisco                                    1314</span><br><span class=\"line\">       Integration Specialist                                $372,000                                New York                                    4804</span><br><span class=\"line\">            Software Engineer                                $163,500                                  London                                    6222</span><br><span class=\"line\">            Pre-Sales Support                                $106,450                                New York                                    8330</span><br><span class=\"line\">              Sales Assistant                                $145,600                                New York                                    3990</span><br><span class=\"line\">  Senior Javascript Developer                                $433,060                               Edinburgh                                    6224</span><br></pre></td></tr></table></figure>"},{"title":"Style Transfer Experiments","date":"2019-12-29T14:08:36.000Z","cover_image":"images/style-transfer.jpg","_content":"\nDeep convolutional neural networks were used to change the patterns on the original pictures.\n\n# Sketch\n<img src=\"s1_1.jpg\" width=\"80%\"/>\n<img src=\"s1_2.jpg\" width=\"80%\" />\n<img src=\"s1_3.jpg\" width=\"80%\" />\n<img src=\"s1_4.jpg\" width=\"80%\" />\n\n# Dark\n<img src=\"s2_1.jpg\" width=\"80%\" />\n<img src=\"s2_2.jpg\" width=\"80%\" />\n<img src=\"s2_3.jpg\" width=\"80%\" />\n<img src=\"s2_4.jpg\" width=\"80%\" />\n\n# Red Animals\n<img src=\"s3_1.jpg\" width=\"80%\" />\n<img src=\"s3_2.jpg\" width=\"80%\" />\n\n# Blue Animals\n<img src=\"s4_1.jpg\" width=\"80%\" />\n<img src=\"s4_2.jpg\" width=\"80%\" />\n","source":"_posts/Style-Transfer-Experiments.md","raw":"---\ntitle: Style Transfer Experiments\ndate: 2019-12-29 11:08:36\ntags: style-transfer\ncover_image: images/style-transfer.jpg\n---\n\nDeep convolutional neural networks were used to change the patterns on the original pictures.\n\n# Sketch\n<img src=\"s1_1.jpg\" width=\"80%\"/>\n<img src=\"s1_2.jpg\" width=\"80%\" />\n<img src=\"s1_3.jpg\" width=\"80%\" />\n<img src=\"s1_4.jpg\" width=\"80%\" />\n\n# Dark\n<img src=\"s2_1.jpg\" width=\"80%\" />\n<img src=\"s2_2.jpg\" width=\"80%\" />\n<img src=\"s2_3.jpg\" width=\"80%\" />\n<img src=\"s2_4.jpg\" width=\"80%\" />\n\n# Red Animals\n<img src=\"s3_1.jpg\" width=\"80%\" />\n<img src=\"s3_2.jpg\" width=\"80%\" />\n\n# Blue Animals\n<img src=\"s4_1.jpg\" width=\"80%\" />\n<img src=\"s4_2.jpg\" width=\"80%\" />\n","slug":"Style-Transfer-Experiments","published":1,"updated":"2020-04-18T19:04:35.549Z","_id":"ck8jb761m0007nlry4nk76xpp","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Deep convolutional neural networks were used to change the patterns on the original pictures.</p>\n<h1 id=\"Sketch\"><a href=\"#Sketch\" class=\"headerlink\" title=\"Sketch\"></a>Sketch</h1><img src=\"s1_1.jpg\" width=\"80%\"/>\n<img src=\"s1_2.jpg\" width=\"80%\" />\n<img src=\"s1_3.jpg\" width=\"80%\" />\n<img src=\"s1_4.jpg\" width=\"80%\" />\n\n<h1 id=\"Dark\"><a href=\"#Dark\" class=\"headerlink\" title=\"Dark\"></a>Dark</h1><img src=\"s2_1.jpg\" width=\"80%\" />\n<img src=\"s2_2.jpg\" width=\"80%\" />\n<img src=\"s2_3.jpg\" width=\"80%\" />\n<img src=\"s2_4.jpg\" width=\"80%\" />\n\n<h1 id=\"Red-Animals\"><a href=\"#Red-Animals\" class=\"headerlink\" title=\"Red Animals\"></a>Red Animals</h1><img src=\"s3_1.jpg\" width=\"80%\" />\n<img src=\"s3_2.jpg\" width=\"80%\" />\n\n<h1 id=\"Blue-Animals\"><a href=\"#Blue-Animals\" class=\"headerlink\" title=\"Blue Animals\"></a>Blue Animals</h1><img src=\"s4_1.jpg\" width=\"80%\" />\n<img src=\"s4_2.jpg\" width=\"80%\" />\n","site":{"data":{}},"excerpt":"","more":"<p>Deep convolutional neural networks were used to change the patterns on the original pictures.</p>\n<h1 id=\"Sketch\"><a href=\"#Sketch\" class=\"headerlink\" title=\"Sketch\"></a>Sketch</h1><img src=\"s1_1.jpg\" width=\"80%\"/>\n<img src=\"s1_2.jpg\" width=\"80%\" />\n<img src=\"s1_3.jpg\" width=\"80%\" />\n<img src=\"s1_4.jpg\" width=\"80%\" />\n\n<h1 id=\"Dark\"><a href=\"#Dark\" class=\"headerlink\" title=\"Dark\"></a>Dark</h1><img src=\"s2_1.jpg\" width=\"80%\" />\n<img src=\"s2_2.jpg\" width=\"80%\" />\n<img src=\"s2_3.jpg\" width=\"80%\" />\n<img src=\"s2_4.jpg\" width=\"80%\" />\n\n<h1 id=\"Red-Animals\"><a href=\"#Red-Animals\" class=\"headerlink\" title=\"Red Animals\"></a>Red Animals</h1><img src=\"s3_1.jpg\" width=\"80%\" />\n<img src=\"s3_2.jpg\" width=\"80%\" />\n\n<h1 id=\"Blue-Animals\"><a href=\"#Blue-Animals\" class=\"headerlink\" title=\"Blue Animals\"></a>Blue Animals</h1><img src=\"s4_1.jpg\" width=\"80%\" />\n<img src=\"s4_2.jpg\" width=\"80%\" />\n"},{"title":"bu3nAmigue - Experimental Indie Band","date":"2019-12-15T14:09:50.000Z","cover_image":"images/bu3namigue.jpg","_content":"\nOn december 2019, [solquemal](https://solquemal.com), [pablito](https://www.instagram.com/plabarta_/) and me formed bu3nAmigue, an artistic collective focused on live coding.\n\n[![IMAGE ALT TEXT HERE](https://i.ytimg.com/vi/stfLFoA8maM/maxresdefault.jpg)](https://www.youtube.com/watch?v=stfLFoA8maM)\n\nYou can check our social networks here:\n- [Instagram](https://www.instagram.com/bu3namigue/)\n- [bandcamp](https://bu3namigue.bandcamp.com/)\n- [YouTube](https://www.youtube.com/channel/UCnjUJE2RUee2IwyopOHQ6wg)\n- [GitHub](https://github.com/bu3namigue/)\n\n\n","source":"_posts/bu3nAmigue-Experimental-Indie-Band.md","raw":"---\ntitle: bu3nAmigue - Experimental Indie Band\ndate: 2019-12-15 11:09:50\ntags:\ncover_image: images/bu3namigue.jpg\n---\n\nOn december 2019, [solquemal](https://solquemal.com), [pablito](https://www.instagram.com/plabarta_/) and me formed bu3nAmigue, an artistic collective focused on live coding.\n\n[![IMAGE ALT TEXT HERE](https://i.ytimg.com/vi/stfLFoA8maM/maxresdefault.jpg)](https://www.youtube.com/watch?v=stfLFoA8maM)\n\nYou can check our social networks here:\n- [Instagram](https://www.instagram.com/bu3namigue/)\n- [bandcamp](https://bu3namigue.bandcamp.com/)\n- [YouTube](https://www.youtube.com/channel/UCnjUJE2RUee2IwyopOHQ6wg)\n- [GitHub](https://github.com/bu3namigue/)\n\n\n","slug":"bu3nAmigue-Experimental-Indie-Band","published":1,"updated":"2020-04-18T18:39:16.510Z","_id":"ck8jb761m0008nlryaj7gb8pi","comments":1,"layout":"post","photos":[],"link":"","content":"<p>On december 2019, <a href=\"https://solquemal.com\" target=\"_blank\" rel=\"noopener\">solquemal</a>, <a href=\"https://www.instagram.com/plabarta_/\" target=\"_blank\" rel=\"noopener\">pablito</a> and me formed bu3nAmigue, an artistic collective focused on live coding.</p>\n<p><a href=\"https://www.youtube.com/watch?v=stfLFoA8maM\" target=\"_blank\" rel=\"noopener\"><img src=\"https://i.ytimg.com/vi/stfLFoA8maM/maxresdefault.jpg\" alt=\"IMAGE ALT TEXT HERE\"></a></p>\n<p>You can check our social networks here:</p>\n<ul>\n<li><a href=\"https://www.instagram.com/bu3namigue/\" target=\"_blank\" rel=\"noopener\">Instagram</a></li>\n<li><a href=\"https://bu3namigue.bandcamp.com/\" target=\"_blank\" rel=\"noopener\">bandcamp</a></li>\n<li><a href=\"https://www.youtube.com/channel/UCnjUJE2RUee2IwyopOHQ6wg\" target=\"_blank\" rel=\"noopener\">YouTube</a></li>\n<li><a href=\"https://github.com/bu3namigue/\" target=\"_blank\" rel=\"noopener\">GitHub</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>On december 2019, <a href=\"https://solquemal.com\" target=\"_blank\" rel=\"noopener\">solquemal</a>, <a href=\"https://www.instagram.com/plabarta_/\" target=\"_blank\" rel=\"noopener\">pablito</a> and me formed bu3nAmigue, an artistic collective focused on live coding.</p>\n<p><a href=\"https://www.youtube.com/watch?v=stfLFoA8maM\" target=\"_blank\" rel=\"noopener\"><img src=\"https://i.ytimg.com/vi/stfLFoA8maM/maxresdefault.jpg\" alt=\"IMAGE ALT TEXT HERE\"></a></p>\n<p>You can check our social networks here:</p>\n<ul>\n<li><a href=\"https://www.instagram.com/bu3namigue/\" target=\"_blank\" rel=\"noopener\">Instagram</a></li>\n<li><a href=\"https://bu3namigue.bandcamp.com/\" target=\"_blank\" rel=\"noopener\">bandcamp</a></li>\n<li><a href=\"https://www.youtube.com/channel/UCnjUJE2RUee2IwyopOHQ6wg\" target=\"_blank\" rel=\"noopener\">YouTube</a></li>\n<li><a href=\"https://github.com/bu3namigue/\" target=\"_blank\" rel=\"noopener\">GitHub</a></li>\n</ul>\n"},{"title":"Coding Psychological Experiments","date":"2019-06-09T21:39:02.000Z","cover_image":"images/psychological.jpg","_content":"\nPsychopy library is a useful framework to develop psychological experiments using Python. In this example I will show how to develop a basic experiment that registers how much time it takes for someone to press a key, then I will save the data as a csv file. The full code can be found [here](https://gist.github.com/mathigatti/3635a6414118e34fa90786fb67b6b7ea).\n\n<img src=\"https://ucarecdn.com/747786fb-53a6-470f-9d21-1c0285d2d320/\" width=\"100%\" border=\"5\" />\n\n## The code\n\n### Libraries\nFirst I import the libraries\n```python\nfrom psychopy import visual, core, event\nimport datetime # Used to register the date of the experiment\nimport pandas as pd # Used to save the data as csv easily\n```\n\n### Setting constants and global variables\n```python\n# Colours\ngray = '#969696'\nblack = '#000000'\nwhite = '#FFFFFF'\n\n# Window parameters\nresolution = [300, 300]\n```\n\n### Defining main functions\n\n#### Window\n\nIn psychopy you define the window where all the screens are going to be displayed like this\n\n```python\ndef window(resolution):\n    fullScreen = False\n    win = visual.Window(resolution,units=\"pix\",  color=gray,\n     colorSpace='hex', fullscr=fullScreen, monitor = \"testMonitor\")\n    win.setMouseVisible(False)\n    return win\n```\n\n#### Screens\n\nWe are going to define the screens now. Here we will specify the text messages, its style, the background colour and all that kind of things. Our program has only two screens, the starter screen that ask you to start, and the stop screen that records how long you took to press the button.\n\n<img src=\"https://ucarecdn.com/75931ec1-0f82-45f1-be76-22004d39dc4f/\" width=\"100%\" border=\"5\" />\n\n```python\ndef loadInstructionsAndFlip(win):\n    background = visual.Rect(win, width=resolution[0]+10,\n     height=resolution[1]+10, fillColor=black, fillColorSpace='hex')\n    msg1 = visual.TextStim(win, text=\"press [ q ] to exit\",\n     pos=(0.0,(-resolution[1]*0.10)), color=white, colorSpace='hex')\n    msg2 = visual.TextStim(win, text=\"press [ n ] to continue\",\n     color=white, colorSpace='hex',alignHoriz='center', alignVert='center')\n    background.draw()\n    msg1.draw()\n    msg2.draw()\n\n    # Elements are only displayed after the flip command is executed\n    win.flip()\n\ndef loadStartScreenAndFlip(win):\n    background = visual.Rect(win, width=resolution[0]+10,\n     height=resolution[1]+10, fillColor=gray, fillColorSpace='hex')\n    msg1 = visual.TextStim(win, text=\"press any key to start\",\n     color=white, colorSpace='hex')\n    background.draw()\n    msg1.draw()\n\n    # Elements are only displayed after the flip command is executed\n    win.flip()\n```\n\n#### Main logic\nHere we implement the main logic of the program. We create the clock that measures the time. We reset it on every iteration and show each screen every time.\n```python\ndef startScreensAndRecordData(win):\n    clock = core.Clock()\n    win.clearBuffer()\n\n    data = []\n    loadStartScreenAndFlip(win)\n    event.waitKeys()\n\n    while True:\n        loadInstructionsAndFlip(win)\n        clock.reset()\n        keys = event.waitKeys(keyList=[\"n\",\"q\"])\n        for key in keys:\n            time = clock.getTime()\n            print(\"You pressed the {} key on {} seconds\"\n                .format(key,round(time,3)))\n            data.append([key,time])\n            if key == \"q\":\n                return data\n            else:\n                loadStartScreenAndFlip(win)\n                event.waitKeys()\n```\n\n#### Puting all together and saving it\nFinally we put everything together and save the file as a CSV using pandas :)\n\n\n```python\ndef main():\n    win = window(resolution)\n    data = startScreensAndRecordData(win)\n\n    pd.DataFrame(data,columns=[\"Key\",\"Time\"])\n    .to_csv('experiment_' + str(datetime.date.today()) + '.csv')\n\n\n```\n\n![](https://ucarecdn.com/e0615065-b962-4851-998e-1d4da0ce1d75/)\n","source":"_posts/Coding-Psychological-Experiments.md","raw":"---\ntitle: Coding Psychological Experiments\ndate: 2019-06-09 18:39:02\ntags:\ncover_image: images/psychological.jpg\n---\n\nPsychopy library is a useful framework to develop psychological experiments using Python. In this example I will show how to develop a basic experiment that registers how much time it takes for someone to press a key, then I will save the data as a csv file. The full code can be found [here](https://gist.github.com/mathigatti/3635a6414118e34fa90786fb67b6b7ea).\n\n<img src=\"https://ucarecdn.com/747786fb-53a6-470f-9d21-1c0285d2d320/\" width=\"100%\" border=\"5\" />\n\n## The code\n\n### Libraries\nFirst I import the libraries\n```python\nfrom psychopy import visual, core, event\nimport datetime # Used to register the date of the experiment\nimport pandas as pd # Used to save the data as csv easily\n```\n\n### Setting constants and global variables\n```python\n# Colours\ngray = '#969696'\nblack = '#000000'\nwhite = '#FFFFFF'\n\n# Window parameters\nresolution = [300, 300]\n```\n\n### Defining main functions\n\n#### Window\n\nIn psychopy you define the window where all the screens are going to be displayed like this\n\n```python\ndef window(resolution):\n    fullScreen = False\n    win = visual.Window(resolution,units=\"pix\",  color=gray,\n     colorSpace='hex', fullscr=fullScreen, monitor = \"testMonitor\")\n    win.setMouseVisible(False)\n    return win\n```\n\n#### Screens\n\nWe are going to define the screens now. Here we will specify the text messages, its style, the background colour and all that kind of things. Our program has only two screens, the starter screen that ask you to start, and the stop screen that records how long you took to press the button.\n\n<img src=\"https://ucarecdn.com/75931ec1-0f82-45f1-be76-22004d39dc4f/\" width=\"100%\" border=\"5\" />\n\n```python\ndef loadInstructionsAndFlip(win):\n    background = visual.Rect(win, width=resolution[0]+10,\n     height=resolution[1]+10, fillColor=black, fillColorSpace='hex')\n    msg1 = visual.TextStim(win, text=\"press [ q ] to exit\",\n     pos=(0.0,(-resolution[1]*0.10)), color=white, colorSpace='hex')\n    msg2 = visual.TextStim(win, text=\"press [ n ] to continue\",\n     color=white, colorSpace='hex',alignHoriz='center', alignVert='center')\n    background.draw()\n    msg1.draw()\n    msg2.draw()\n\n    # Elements are only displayed after the flip command is executed\n    win.flip()\n\ndef loadStartScreenAndFlip(win):\n    background = visual.Rect(win, width=resolution[0]+10,\n     height=resolution[1]+10, fillColor=gray, fillColorSpace='hex')\n    msg1 = visual.TextStim(win, text=\"press any key to start\",\n     color=white, colorSpace='hex')\n    background.draw()\n    msg1.draw()\n\n    # Elements are only displayed after the flip command is executed\n    win.flip()\n```\n\n#### Main logic\nHere we implement the main logic of the program. We create the clock that measures the time. We reset it on every iteration and show each screen every time.\n```python\ndef startScreensAndRecordData(win):\n    clock = core.Clock()\n    win.clearBuffer()\n\n    data = []\n    loadStartScreenAndFlip(win)\n    event.waitKeys()\n\n    while True:\n        loadInstructionsAndFlip(win)\n        clock.reset()\n        keys = event.waitKeys(keyList=[\"n\",\"q\"])\n        for key in keys:\n            time = clock.getTime()\n            print(\"You pressed the {} key on {} seconds\"\n                .format(key,round(time,3)))\n            data.append([key,time])\n            if key == \"q\":\n                return data\n            else:\n                loadStartScreenAndFlip(win)\n                event.waitKeys()\n```\n\n#### Puting all together and saving it\nFinally we put everything together and save the file as a CSV using pandas :)\n\n\n```python\ndef main():\n    win = window(resolution)\n    data = startScreensAndRecordData(win)\n\n    pd.DataFrame(data,columns=[\"Key\",\"Time\"])\n    .to_csv('experiment_' + str(datetime.date.today()) + '.csv')\n\n\n```\n\n![](https://ucarecdn.com/e0615065-b962-4851-998e-1d4da0ce1d75/)\n","slug":"Coding-Psychological-Experiments","published":1,"updated":"2020-04-18T20:16:17.389Z","_id":"ck8m5369200068gryfyz8at8b","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Psychopy library is a useful framework to develop psychological experiments using Python. In this example I will show how to develop a basic experiment that registers how much time it takes for someone to press a key, then I will save the data as a csv file. The full code can be found <a href=\"https://gist.github.com/mathigatti/3635a6414118e34fa90786fb67b6b7ea\" target=\"_blank\" rel=\"noopener\">here</a>.</p>\n<img src=\"https://ucarecdn.com/747786fb-53a6-470f-9d21-1c0285d2d320/\" width=\"100%\" border=\"5\" />\n\n<h2 id=\"The-code\"><a href=\"#The-code\" class=\"headerlink\" title=\"The code\"></a>The code</h2><h3 id=\"Libraries\"><a href=\"#Libraries\" class=\"headerlink\" title=\"Libraries\"></a>Libraries</h3><p>First I import the libraries</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> psychopy <span class=\"keyword\">import</span> visual, core, event</span><br><span class=\"line\"><span class=\"keyword\">import</span> datetime <span class=\"comment\"># Used to register the date of the experiment</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd <span class=\"comment\"># Used to save the data as csv easily</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Setting-constants-and-global-variables\"><a href=\"#Setting-constants-and-global-variables\" class=\"headerlink\" title=\"Setting constants and global variables\"></a>Setting constants and global variables</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Colours</span></span><br><span class=\"line\">gray = <span class=\"string\">'#969696'</span></span><br><span class=\"line\">black = <span class=\"string\">'#000000'</span></span><br><span class=\"line\">white = <span class=\"string\">'#FFFFFF'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Window parameters</span></span><br><span class=\"line\">resolution = [<span class=\"number\">300</span>, <span class=\"number\">300</span>]</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Defining-main-functions\"><a href=\"#Defining-main-functions\" class=\"headerlink\" title=\"Defining main functions\"></a>Defining main functions</h3><h4 id=\"Window\"><a href=\"#Window\" class=\"headerlink\" title=\"Window\"></a>Window</h4><p>In psychopy you define the window where all the screens are going to be displayed like this</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">window</span><span class=\"params\">(resolution)</span>:</span></span><br><span class=\"line\">    fullScreen = <span class=\"literal\">False</span></span><br><span class=\"line\">    win = visual.Window(resolution,units=<span class=\"string\">\"pix\"</span>,  color=gray,</span><br><span class=\"line\">     colorSpace=<span class=\"string\">'hex'</span>, fullscr=fullScreen, monitor = <span class=\"string\">\"testMonitor\"</span>)</span><br><span class=\"line\">    win.setMouseVisible(<span class=\"literal\">False</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> win</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Screens\"><a href=\"#Screens\" class=\"headerlink\" title=\"Screens\"></a>Screens</h4><p>We are going to define the screens now. Here we will specify the text messages, its style, the background colour and all that kind of things. Our program has only two screens, the starter screen that ask you to start, and the stop screen that records how long you took to press the button.</p>\n<img src=\"https://ucarecdn.com/75931ec1-0f82-45f1-be76-22004d39dc4f/\" width=\"100%\" border=\"5\" />\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">loadInstructionsAndFlip</span><span class=\"params\">(win)</span>:</span></span><br><span class=\"line\">    background = visual.Rect(win, width=resolution[<span class=\"number\">0</span>]+<span class=\"number\">10</span>,</span><br><span class=\"line\">     height=resolution[<span class=\"number\">1</span>]+<span class=\"number\">10</span>, fillColor=black, fillColorSpace=<span class=\"string\">'hex'</span>)</span><br><span class=\"line\">    msg1 = visual.TextStim(win, text=<span class=\"string\">\"press [ q ] to exit\"</span>,</span><br><span class=\"line\">     pos=(<span class=\"number\">0.0</span>,(-resolution[<span class=\"number\">1</span>]*<span class=\"number\">0.10</span>)), color=white, colorSpace=<span class=\"string\">'hex'</span>)</span><br><span class=\"line\">    msg2 = visual.TextStim(win, text=<span class=\"string\">\"press [ n ] to continue\"</span>,</span><br><span class=\"line\">     color=white, colorSpace=<span class=\"string\">'hex'</span>,alignHoriz=<span class=\"string\">'center'</span>, alignVert=<span class=\"string\">'center'</span>)</span><br><span class=\"line\">    background.draw()</span><br><span class=\"line\">    msg1.draw()</span><br><span class=\"line\">    msg2.draw()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Elements are only displayed after the flip command is executed</span></span><br><span class=\"line\">    win.flip()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">loadStartScreenAndFlip</span><span class=\"params\">(win)</span>:</span></span><br><span class=\"line\">    background = visual.Rect(win, width=resolution[<span class=\"number\">0</span>]+<span class=\"number\">10</span>,</span><br><span class=\"line\">     height=resolution[<span class=\"number\">1</span>]+<span class=\"number\">10</span>, fillColor=gray, fillColorSpace=<span class=\"string\">'hex'</span>)</span><br><span class=\"line\">    msg1 = visual.TextStim(win, text=<span class=\"string\">\"press any key to start\"</span>,</span><br><span class=\"line\">     color=white, colorSpace=<span class=\"string\">'hex'</span>)</span><br><span class=\"line\">    background.draw()</span><br><span class=\"line\">    msg1.draw()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Elements are only displayed after the flip command is executed</span></span><br><span class=\"line\">    win.flip()</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Main-logic\"><a href=\"#Main-logic\" class=\"headerlink\" title=\"Main logic\"></a>Main logic</h4><p>Here we implement the main logic of the program. We create the clock that measures the time. We reset it on every iteration and show each screen every time.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">startScreensAndRecordData</span><span class=\"params\">(win)</span>:</span></span><br><span class=\"line\">    clock = core.Clock()</span><br><span class=\"line\">    win.clearBuffer()</span><br><span class=\"line\"></span><br><span class=\"line\">    data = []</span><br><span class=\"line\">    loadStartScreenAndFlip(win)</span><br><span class=\"line\">    event.waitKeys()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">        loadInstructionsAndFlip(win)</span><br><span class=\"line\">        clock.reset()</span><br><span class=\"line\">        keys = event.waitKeys(keyList=[<span class=\"string\">\"n\"</span>,<span class=\"string\">\"q\"</span>])</span><br><span class=\"line\">        <span class=\"keyword\">for</span> key <span class=\"keyword\">in</span> keys:</span><br><span class=\"line\">            time = clock.getTime()</span><br><span class=\"line\">            print(<span class=\"string\">\"You pressed the &#123;&#125; key on &#123;&#125; seconds\"</span></span><br><span class=\"line\">                .format(key,round(time,<span class=\"number\">3</span>)))</span><br><span class=\"line\">            data.append([key,time])</span><br><span class=\"line\">            <span class=\"keyword\">if</span> key == <span class=\"string\">\"q\"</span>:</span><br><span class=\"line\">                <span class=\"keyword\">return</span> data</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                loadStartScreenAndFlip(win)</span><br><span class=\"line\">                event.waitKeys()</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Puting-all-together-and-saving-it\"><a href=\"#Puting-all-together-and-saving-it\" class=\"headerlink\" title=\"Puting all together and saving it\"></a>Puting all together and saving it</h4><p>Finally we put everything together and save the file as a CSV using pandas :)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    win = window(resolution)</span><br><span class=\"line\">    data = startScreensAndRecordData(win)</span><br><span class=\"line\"></span><br><span class=\"line\">    pd.DataFrame(data,columns=[<span class=\"string\">\"Key\"</span>,<span class=\"string\">\"Time\"</span>])</span><br><span class=\"line\">    .to_csv(<span class=\"string\">'experiment_'</span> + str(datetime.date.today()) + <span class=\"string\">'.csv'</span>)</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://ucarecdn.com/e0615065-b962-4851-998e-1d4da0ce1d75/\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Psychopy library is a useful framework to develop psychological experiments using Python. In this example I will show how to develop a basic experiment that registers how much time it takes for someone to press a key, then I will save the data as a csv file. The full code can be found <a href=\"https://gist.github.com/mathigatti/3635a6414118e34fa90786fb67b6b7ea\" target=\"_blank\" rel=\"noopener\">here</a>.</p>\n<img src=\"https://ucarecdn.com/747786fb-53a6-470f-9d21-1c0285d2d320/\" width=\"100%\" border=\"5\" />\n\n<h2 id=\"The-code\"><a href=\"#The-code\" class=\"headerlink\" title=\"The code\"></a>The code</h2><h3 id=\"Libraries\"><a href=\"#Libraries\" class=\"headerlink\" title=\"Libraries\"></a>Libraries</h3><p>First I import the libraries</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> psychopy <span class=\"keyword\">import</span> visual, core, event</span><br><span class=\"line\"><span class=\"keyword\">import</span> datetime <span class=\"comment\"># Used to register the date of the experiment</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd <span class=\"comment\"># Used to save the data as csv easily</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Setting-constants-and-global-variables\"><a href=\"#Setting-constants-and-global-variables\" class=\"headerlink\" title=\"Setting constants and global variables\"></a>Setting constants and global variables</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Colours</span></span><br><span class=\"line\">gray = <span class=\"string\">'#969696'</span></span><br><span class=\"line\">black = <span class=\"string\">'#000000'</span></span><br><span class=\"line\">white = <span class=\"string\">'#FFFFFF'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Window parameters</span></span><br><span class=\"line\">resolution = [<span class=\"number\">300</span>, <span class=\"number\">300</span>]</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Defining-main-functions\"><a href=\"#Defining-main-functions\" class=\"headerlink\" title=\"Defining main functions\"></a>Defining main functions</h3><h4 id=\"Window\"><a href=\"#Window\" class=\"headerlink\" title=\"Window\"></a>Window</h4><p>In psychopy you define the window where all the screens are going to be displayed like this</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">window</span><span class=\"params\">(resolution)</span>:</span></span><br><span class=\"line\">    fullScreen = <span class=\"literal\">False</span></span><br><span class=\"line\">    win = visual.Window(resolution,units=<span class=\"string\">\"pix\"</span>,  color=gray,</span><br><span class=\"line\">     colorSpace=<span class=\"string\">'hex'</span>, fullscr=fullScreen, monitor = <span class=\"string\">\"testMonitor\"</span>)</span><br><span class=\"line\">    win.setMouseVisible(<span class=\"literal\">False</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> win</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Screens\"><a href=\"#Screens\" class=\"headerlink\" title=\"Screens\"></a>Screens</h4><p>We are going to define the screens now. Here we will specify the text messages, its style, the background colour and all that kind of things. Our program has only two screens, the starter screen that ask you to start, and the stop screen that records how long you took to press the button.</p>\n<img src=\"https://ucarecdn.com/75931ec1-0f82-45f1-be76-22004d39dc4f/\" width=\"100%\" border=\"5\" />\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">loadInstructionsAndFlip</span><span class=\"params\">(win)</span>:</span></span><br><span class=\"line\">    background = visual.Rect(win, width=resolution[<span class=\"number\">0</span>]+<span class=\"number\">10</span>,</span><br><span class=\"line\">     height=resolution[<span class=\"number\">1</span>]+<span class=\"number\">10</span>, fillColor=black, fillColorSpace=<span class=\"string\">'hex'</span>)</span><br><span class=\"line\">    msg1 = visual.TextStim(win, text=<span class=\"string\">\"press [ q ] to exit\"</span>,</span><br><span class=\"line\">     pos=(<span class=\"number\">0.0</span>,(-resolution[<span class=\"number\">1</span>]*<span class=\"number\">0.10</span>)), color=white, colorSpace=<span class=\"string\">'hex'</span>)</span><br><span class=\"line\">    msg2 = visual.TextStim(win, text=<span class=\"string\">\"press [ n ] to continue\"</span>,</span><br><span class=\"line\">     color=white, colorSpace=<span class=\"string\">'hex'</span>,alignHoriz=<span class=\"string\">'center'</span>, alignVert=<span class=\"string\">'center'</span>)</span><br><span class=\"line\">    background.draw()</span><br><span class=\"line\">    msg1.draw()</span><br><span class=\"line\">    msg2.draw()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Elements are only displayed after the flip command is executed</span></span><br><span class=\"line\">    win.flip()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">loadStartScreenAndFlip</span><span class=\"params\">(win)</span>:</span></span><br><span class=\"line\">    background = visual.Rect(win, width=resolution[<span class=\"number\">0</span>]+<span class=\"number\">10</span>,</span><br><span class=\"line\">     height=resolution[<span class=\"number\">1</span>]+<span class=\"number\">10</span>, fillColor=gray, fillColorSpace=<span class=\"string\">'hex'</span>)</span><br><span class=\"line\">    msg1 = visual.TextStim(win, text=<span class=\"string\">\"press any key to start\"</span>,</span><br><span class=\"line\">     color=white, colorSpace=<span class=\"string\">'hex'</span>)</span><br><span class=\"line\">    background.draw()</span><br><span class=\"line\">    msg1.draw()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Elements are only displayed after the flip command is executed</span></span><br><span class=\"line\">    win.flip()</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Main-logic\"><a href=\"#Main-logic\" class=\"headerlink\" title=\"Main logic\"></a>Main logic</h4><p>Here we implement the main logic of the program. We create the clock that measures the time. We reset it on every iteration and show each screen every time.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">startScreensAndRecordData</span><span class=\"params\">(win)</span>:</span></span><br><span class=\"line\">    clock = core.Clock()</span><br><span class=\"line\">    win.clearBuffer()</span><br><span class=\"line\"></span><br><span class=\"line\">    data = []</span><br><span class=\"line\">    loadStartScreenAndFlip(win)</span><br><span class=\"line\">    event.waitKeys()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">        loadInstructionsAndFlip(win)</span><br><span class=\"line\">        clock.reset()</span><br><span class=\"line\">        keys = event.waitKeys(keyList=[<span class=\"string\">\"n\"</span>,<span class=\"string\">\"q\"</span>])</span><br><span class=\"line\">        <span class=\"keyword\">for</span> key <span class=\"keyword\">in</span> keys:</span><br><span class=\"line\">            time = clock.getTime()</span><br><span class=\"line\">            print(<span class=\"string\">\"You pressed the &#123;&#125; key on &#123;&#125; seconds\"</span></span><br><span class=\"line\">                .format(key,round(time,<span class=\"number\">3</span>)))</span><br><span class=\"line\">            data.append([key,time])</span><br><span class=\"line\">            <span class=\"keyword\">if</span> key == <span class=\"string\">\"q\"</span>:</span><br><span class=\"line\">                <span class=\"keyword\">return</span> data</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                loadStartScreenAndFlip(win)</span><br><span class=\"line\">                event.waitKeys()</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Puting-all-together-and-saving-it\"><a href=\"#Puting-all-together-and-saving-it\" class=\"headerlink\" title=\"Puting all together and saving it\"></a>Puting all together and saving it</h4><p>Finally we put everything together and save the file as a CSV using pandas :)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    win = window(resolution)</span><br><span class=\"line\">    data = startScreensAndRecordData(win)</span><br><span class=\"line\"></span><br><span class=\"line\">    pd.DataFrame(data,columns=[<span class=\"string\">\"Key\"</span>,<span class=\"string\">\"Time\"</span>])</span><br><span class=\"line\">    .to_csv(<span class=\"string\">'experiment_'</span> + str(datetime.date.today()) + <span class=\"string\">'.csv'</span>)</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://ucarecdn.com/e0615065-b962-4851-998e-1d4da0ce1d75/\" alt=\"\"></p>\n"},{"title":"Computing brain connectivity using portable devices - Master's Thesis","date":"2018-04-04T21:40:41.000Z","cover_image":"images/emotiv.png","_content":"\nThe topic of my master's thesis was neuroscience. I studied how to use low cost portable electroenchephalographs for advanced  connectivity studies. [Here](https://github.com/mathigatti/EmotivExperiments) is the code for the experiments I coded and [here](https://github.com/mathigatti/EmotivClassifier) the classifiers I used in my thesis to infer different states based on neural connectivity. These things together with the great work of Marcos Pietto and his team ended up in the publications of [this](https://www.ncbi.nlm.nih.gov/pubmed/30475814) paper.\n\n![](emotiv.jpg)\n\n## Abstract\n\nThis is the abstract of my thesis, you can read the full version [here](http://dc.sigedep.exactas.uba.ar/media/academic/grade/thesis/Tesis_Mathias_Gatti.pdf) (It's in Spanish).\n\n<i>\nElectroencephalography (EEG) studies have shown to be a fundamental tool in the understanding of human cognitive processes and as a complementary method for clinical diagnosis. EEG recordings are usually restricted to the lab’s environment, which is an important limitation to the study of populations that are difficult to move to the lab or that this environment causes an effect by itself (such as little naturalness or stress). Recently, new EEG equipment at a significant lower cost and greater portability emerged mainly for gaming. However, the use of this equipment could open the possibility in the long term of application of different clinical and research protocols in more ecologically valid environments.\n\nIt is possible to build networks from the EEG recordings by looking at the similarity between the different electrodes, but there are many ways to define this similarity. In this thesis, we aimed to compare the resulting network by applying different measures, in terms of their robustness and their ability to predict different attributes of the subjects.\n\nThus, in the first place, we developed an experimentation environment that allowed both data collection in the lab and massive data collection in the schools. Two data sets were analyzed, the first including the low-cost EEG and the high-resolution EEG in adults, and the second with only the low-cost EEG in preschool children at the schools.\n\nThe results showed that some similarity measures are robust enough to analyze brain activity at the level of networks using the Emotiv system. In particular, we performed different experiments using the adult dataset, of which the PLV (Phase Locking value) and the correlation measures (both Spearman and Pearson) consistently gave the best results. Then, the preschool children dataset were analyzed using these measures and some individual variables, such as sleep level, sex and the distinction between open and closed eyes, were successfully predicted (AUC>0.67). As a final step, the code was released online, allowing anyone to replicate the data collection and connectivity analysis with the Emotiv system.\n\nThis thesis paves the way for the massive recording of brain activity with different paradigms and, in particular, the study of changes in brain connectivity throughout development, in more ecologically valid environments.\n</i>","source":"_posts/Computing-brain-connectivity-using-portable-devices-Master-s-Thesis.md","raw":"---\ntitle: Computing brain connectivity using portable devices - Master's Thesis\ndate: 2018-04-04 18:40:41\ntags: neuroscience\ncover_image: images/emotiv.png\n---\n\nThe topic of my master's thesis was neuroscience. I studied how to use low cost portable electroenchephalographs for advanced  connectivity studies. [Here](https://github.com/mathigatti/EmotivExperiments) is the code for the experiments I coded and [here](https://github.com/mathigatti/EmotivClassifier) the classifiers I used in my thesis to infer different states based on neural connectivity. These things together with the great work of Marcos Pietto and his team ended up in the publications of [this](https://www.ncbi.nlm.nih.gov/pubmed/30475814) paper.\n\n![](emotiv.jpg)\n\n## Abstract\n\nThis is the abstract of my thesis, you can read the full version [here](http://dc.sigedep.exactas.uba.ar/media/academic/grade/thesis/Tesis_Mathias_Gatti.pdf) (It's in Spanish).\n\n<i>\nElectroencephalography (EEG) studies have shown to be a fundamental tool in the understanding of human cognitive processes and as a complementary method for clinical diagnosis. EEG recordings are usually restricted to the lab’s environment, which is an important limitation to the study of populations that are difficult to move to the lab or that this environment causes an effect by itself (such as little naturalness or stress). Recently, new EEG equipment at a significant lower cost and greater portability emerged mainly for gaming. However, the use of this equipment could open the possibility in the long term of application of different clinical and research protocols in more ecologically valid environments.\n\nIt is possible to build networks from the EEG recordings by looking at the similarity between the different electrodes, but there are many ways to define this similarity. In this thesis, we aimed to compare the resulting network by applying different measures, in terms of their robustness and their ability to predict different attributes of the subjects.\n\nThus, in the first place, we developed an experimentation environment that allowed both data collection in the lab and massive data collection in the schools. Two data sets were analyzed, the first including the low-cost EEG and the high-resolution EEG in adults, and the second with only the low-cost EEG in preschool children at the schools.\n\nThe results showed that some similarity measures are robust enough to analyze brain activity at the level of networks using the Emotiv system. In particular, we performed different experiments using the adult dataset, of which the PLV (Phase Locking value) and the correlation measures (both Spearman and Pearson) consistently gave the best results. Then, the preschool children dataset were analyzed using these measures and some individual variables, such as sleep level, sex and the distinction between open and closed eyes, were successfully predicted (AUC>0.67). As a final step, the code was released online, allowing anyone to replicate the data collection and connectivity analysis with the Emotiv system.\n\nThis thesis paves the way for the massive recording of brain activity with different paradigms and, in particular, the study of changes in brain connectivity throughout development, in more ecologically valid environments.\n</i>","slug":"Computing-brain-connectivity-using-portable-devices-Master-s-Thesis","published":1,"updated":"2020-04-18T20:00:15.910Z","_id":"ck8m55ato00078gry1hg55s8h","comments":1,"layout":"post","photos":[],"link":"","content":"<p>The topic of my master’s thesis was neuroscience. I studied how to use low cost portable electroenchephalographs for advanced  connectivity studies. <a href=\"https://github.com/mathigatti/EmotivExperiments\" target=\"_blank\" rel=\"noopener\">Here</a> is the code for the experiments I coded and <a href=\"https://github.com/mathigatti/EmotivClassifier\" target=\"_blank\" rel=\"noopener\">here</a> the classifiers I used in my thesis to infer different states based on neural connectivity. These things together with the great work of Marcos Pietto and his team ended up in the publications of <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/30475814\" target=\"_blank\" rel=\"noopener\">this</a> paper.</p>\n<p><img src=\"emotiv.jpg\" alt=\"\"></p>\n<h2 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h2><p>This is the abstract of my thesis, you can read the full version <a href=\"http://dc.sigedep.exactas.uba.ar/media/academic/grade/thesis/Tesis_Mathias_Gatti.pdf\" target=\"_blank\" rel=\"noopener\">here</a> (It’s in Spanish).</p>\n<i>\nElectroencephalography (EEG) studies have shown to be a fundamental tool in the understanding of human cognitive processes and as a complementary method for clinical diagnosis. EEG recordings are usually restricted to the lab’s environment, which is an important limitation to the study of populations that are difficult to move to the lab or that this environment causes an effect by itself (such as little naturalness or stress). Recently, new EEG equipment at a significant lower cost and greater portability emerged mainly for gaming. However, the use of this equipment could open the possibility in the long term of application of different clinical and research protocols in more ecologically valid environments.\n\n<p>It is possible to build networks from the EEG recordings by looking at the similarity between the different electrodes, but there are many ways to define this similarity. In this thesis, we aimed to compare the resulting network by applying different measures, in terms of their robustness and their ability to predict different attributes of the subjects.</p>\n<p>Thus, in the first place, we developed an experimentation environment that allowed both data collection in the lab and massive data collection in the schools. Two data sets were analyzed, the first including the low-cost EEG and the high-resolution EEG in adults, and the second with only the low-cost EEG in preschool children at the schools.</p>\n<p>The results showed that some similarity measures are robust enough to analyze brain activity at the level of networks using the Emotiv system. In particular, we performed different experiments using the adult dataset, of which the PLV (Phase Locking value) and the correlation measures (both Spearman and Pearson) consistently gave the best results. Then, the preschool children dataset were analyzed using these measures and some individual variables, such as sleep level, sex and the distinction between open and closed eyes, were successfully predicted (AUC&gt;0.67). As a final step, the code was released online, allowing anyone to replicate the data collection and connectivity analysis with the Emotiv system.</p>\n<p>This thesis paves the way for the massive recording of brain activity with different paradigms and, in particular, the study of changes in brain connectivity throughout development, in more ecologically valid environments.<br></i></p>\n","site":{"data":{}},"excerpt":"","more":"<p>The topic of my master’s thesis was neuroscience. I studied how to use low cost portable electroenchephalographs for advanced  connectivity studies. <a href=\"https://github.com/mathigatti/EmotivExperiments\" target=\"_blank\" rel=\"noopener\">Here</a> is the code for the experiments I coded and <a href=\"https://github.com/mathigatti/EmotivClassifier\" target=\"_blank\" rel=\"noopener\">here</a> the classifiers I used in my thesis to infer different states based on neural connectivity. These things together with the great work of Marcos Pietto and his team ended up in the publications of <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/30475814\" target=\"_blank\" rel=\"noopener\">this</a> paper.</p>\n<p><img src=\"emotiv.jpg\" alt=\"\"></p>\n<h2 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h2><p>This is the abstract of my thesis, you can read the full version <a href=\"http://dc.sigedep.exactas.uba.ar/media/academic/grade/thesis/Tesis_Mathias_Gatti.pdf\" target=\"_blank\" rel=\"noopener\">here</a> (It’s in Spanish).</p>\n<i>\nElectroencephalography (EEG) studies have shown to be a fundamental tool in the understanding of human cognitive processes and as a complementary method for clinical diagnosis. EEG recordings are usually restricted to the lab’s environment, which is an important limitation to the study of populations that are difficult to move to the lab or that this environment causes an effect by itself (such as little naturalness or stress). Recently, new EEG equipment at a significant lower cost and greater portability emerged mainly for gaming. However, the use of this equipment could open the possibility in the long term of application of different clinical and research protocols in more ecologically valid environments.\n\n<p>It is possible to build networks from the EEG recordings by looking at the similarity between the different electrodes, but there are many ways to define this similarity. In this thesis, we aimed to compare the resulting network by applying different measures, in terms of their robustness and their ability to predict different attributes of the subjects.</p>\n<p>Thus, in the first place, we developed an experimentation environment that allowed both data collection in the lab and massive data collection in the schools. Two data sets were analyzed, the first including the low-cost EEG and the high-resolution EEG in adults, and the second with only the low-cost EEG in preschool children at the schools.</p>\n<p>The results showed that some similarity measures are robust enough to analyze brain activity at the level of networks using the Emotiv system. In particular, we performed different experiments using the adult dataset, of which the PLV (Phase Locking value) and the correlation measures (both Spearman and Pearson) consistently gave the best results. Then, the preschool children dataset were analyzed using these measures and some individual variables, such as sleep level, sex and the distinction between open and closed eyes, were successfully predicted (AUC&gt;0.67). As a final step, the code was released online, allowing anyone to replicate the data collection and connectivity analysis with the Emotiv system.</p>\n<p>This thesis paves the way for the massive recording of brain activity with different paradigms and, in particular, the study of changes in brain connectivity throughout development, in more ecologically valid environments.<br></i></p>\n"},{"title":"Looking for the formula of beauty","date":"2019-08-05T21:41:46.000Z","cover_image":"images/pattern2.jpg","_content":"\nSome time ago I created [this](https://gist.github.com/mathigatti/439a0e81556f2698c7db4f41189d201f) small script to convert numbers into patterns. I'm not going to explain how the script works in detail but it's inspired on [Stephen Wolfram's Elementary Cellular Automatas](https://en.wikipedia.org/wiki/Elementary_cellular_automaton) which converts numbers like 30 into binary (00011110) and then interprets the digits as turning ON or OFF of 8 different basic rules (In that case there are 4 rules activated, rule 4, 5, 6 and 7) that define when to turn ON and OFF a pixel in the image.\n\n![ElementaryCARule030_1000.gif](https://ucarecdn.com/a4323adb-4c13-4c4f-a32d-97f86468a1f0/)\n\nUsing this I can generate an infinite number of different patterns, the problem is that most of them are not really interesting and I have no time to check them one by one. That's why in this post I explain how I tried to automate the process of finding out the most interesting/beautiful cellular automatas.\n\n## Clusterization\nMy goal is to group the patterns by its beauty. I do this using a clustering algorithm based on features frequently attributed to beauty such as fractal dimensionality and compression efficiency. You can read more about these features here: [Forsythe, Alex, et al. \"Predicting beauty: fractal dimension and visual complexity in art.\" British journal of psychology 102.1 (2011): 49-70](https://www.researchgate.net/publication/49761486_Predicting_beauty_Fractal_dimension_and_visual_complexity_in_art).\n\n## The Code\nThe full code is [here](https://github.com/mathigatti/CellularAutomataClassification) but I also uploaded it into colab [here](https://colab.research.google.com/drive/1FFNRZuRW7lkKi1LnbMR-d8KI0EADl871) so you can run everything from your web browser.\n\n### Defining clustering attributes\nFirst I define the previously mentioned attributes, fractal dimension (Code taken from [here](https://gist.github.com/rougier/e5eafc276a4e54f516ed5559df4242c0)) and compression score (The weight of a raw tiff image over its weight compressed as a gif image).\n\n```\nfrom fractaldimension import fractal_dimension\nimport cv2\nimport os\n\ndef fractalDimension(number):\n    im = cv2.imread('images/'+str(number)+'.tiff',\n    cv2.IMREAD_GRAYSCALE)\n    newDimension = fractal_dimension(im, 0.9)\n    return newDimension\n\ndef compressionScore(number):\n    statinfo = os.stat('images/'+str(number)+'.gif')\n    gif = statinfo.st_size # size of the file\n    \n    statinfo = os.stat('images/'+str(number)+'.tiff')\n    tiff = statinfo.st_size # size of the file\n    \n    return tiff/gif\n```\n\n### Clustering\nThere are several clustering algorithms, you can choose the one that best fits your use case.\n\n<img src=\"https://ucarecdn.com/a6d86443-9072-44f0-b032-ccede2fe4073/\" width=\"100%\" border=\"5\" />\n\nIn my case I ended up using Agglomerative Clustering which captures better the clusters generated by this dataset.\n\nYou need to specify the number of clusters, I tried with different numbers, at the end I chose 5 since it grouped them well from null patterns to crazy and chaotic ones.\n\n```\nfrom sklearn.cluster import AgglomerativeClustering\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\n\n# Applying clustering algorithm\nclustering = AgglomerativeClustering(n_clusters=5)\n.fit(df[['Fractal Dimension','Compression Eficciency']].values)\ndf[\"cluster\"] = clustering.labels_\n\n# Plotting results\nfig, ax = plt.subplots()\ncmap = cm.get_cmap('gist_rainbow')\nax = df.plot(kind='scatter', x='Fractal Dimension',\n\ty='Compression Eficciency',\n\tcmap=cmap, c='cluster',ax=ax)\nplt.show()\n```\n![descarga (5).png](https://ucarecdn.com/4fe8f003-2d3f-4296-8c24-9283bb587e2b/)\n\n## Results\nHere I show some samples of each cluster. I sorted them from the simplest ones to the most complex. As you can see this method is useful to identify and discard uninteresting patterns such us the ones from the Cluster 0. It's also useful to identify the most beautiful patterns, most of the best patterns I found are from the Cluster 3, the one with big complexity but not the biggest fractal dimension.\n\n### Cluster 0 (Null patterns)\n![descarga.png](https://ucarecdn.com/6f41e3ce-45dd-4b8e-aa00-b96fde1f09b4/)\n\n### Cluster 1\n![descarga (1).png](https://ucarecdn.com/565971db-1047-4100-92aa-c4feca3697ef/)\n\n### Cluster 2\n<img src=\"https://ucarecdn.com/98775929-3cdc-4ff7-8dbb-0038663896bd/\" width=\"100%\" border=\"5\" />\n\n### Cluster 3\n<img src=\"https://ucarecdn.com/8f4a6dcf-b501-4b8a-bcc0-0b4822b6c26e/\" width=\"100%\" border=\"5\" />\n\n### Cluster 4 (Crazy and chaotic patterns)\n<img src=\"https://ucarecdn.com/b7066ecc-a054-4d34-9ec6-e9ef521fad85/\" width=\"100%\" border=\"5\" />\n","source":"_posts/Looking-for-the-beauty-formula.md","raw":"---\ntitle: Looking for the formula of beauty\ndate: 2019-08-05 18:41:46\ntags: cellular-automata\ncover_image: images/pattern2.jpg\n---\n\nSome time ago I created [this](https://gist.github.com/mathigatti/439a0e81556f2698c7db4f41189d201f) small script to convert numbers into patterns. I'm not going to explain how the script works in detail but it's inspired on [Stephen Wolfram's Elementary Cellular Automatas](https://en.wikipedia.org/wiki/Elementary_cellular_automaton) which converts numbers like 30 into binary (00011110) and then interprets the digits as turning ON or OFF of 8 different basic rules (In that case there are 4 rules activated, rule 4, 5, 6 and 7) that define when to turn ON and OFF a pixel in the image.\n\n![ElementaryCARule030_1000.gif](https://ucarecdn.com/a4323adb-4c13-4c4f-a32d-97f86468a1f0/)\n\nUsing this I can generate an infinite number of different patterns, the problem is that most of them are not really interesting and I have no time to check them one by one. That's why in this post I explain how I tried to automate the process of finding out the most interesting/beautiful cellular automatas.\n\n## Clusterization\nMy goal is to group the patterns by its beauty. I do this using a clustering algorithm based on features frequently attributed to beauty such as fractal dimensionality and compression efficiency. You can read more about these features here: [Forsythe, Alex, et al. \"Predicting beauty: fractal dimension and visual complexity in art.\" British journal of psychology 102.1 (2011): 49-70](https://www.researchgate.net/publication/49761486_Predicting_beauty_Fractal_dimension_and_visual_complexity_in_art).\n\n## The Code\nThe full code is [here](https://github.com/mathigatti/CellularAutomataClassification) but I also uploaded it into colab [here](https://colab.research.google.com/drive/1FFNRZuRW7lkKi1LnbMR-d8KI0EADl871) so you can run everything from your web browser.\n\n### Defining clustering attributes\nFirst I define the previously mentioned attributes, fractal dimension (Code taken from [here](https://gist.github.com/rougier/e5eafc276a4e54f516ed5559df4242c0)) and compression score (The weight of a raw tiff image over its weight compressed as a gif image).\n\n```\nfrom fractaldimension import fractal_dimension\nimport cv2\nimport os\n\ndef fractalDimension(number):\n    im = cv2.imread('images/'+str(number)+'.tiff',\n    cv2.IMREAD_GRAYSCALE)\n    newDimension = fractal_dimension(im, 0.9)\n    return newDimension\n\ndef compressionScore(number):\n    statinfo = os.stat('images/'+str(number)+'.gif')\n    gif = statinfo.st_size # size of the file\n    \n    statinfo = os.stat('images/'+str(number)+'.tiff')\n    tiff = statinfo.st_size # size of the file\n    \n    return tiff/gif\n```\n\n### Clustering\nThere are several clustering algorithms, you can choose the one that best fits your use case.\n\n<img src=\"https://ucarecdn.com/a6d86443-9072-44f0-b032-ccede2fe4073/\" width=\"100%\" border=\"5\" />\n\nIn my case I ended up using Agglomerative Clustering which captures better the clusters generated by this dataset.\n\nYou need to specify the number of clusters, I tried with different numbers, at the end I chose 5 since it grouped them well from null patterns to crazy and chaotic ones.\n\n```\nfrom sklearn.cluster import AgglomerativeClustering\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\n\n# Applying clustering algorithm\nclustering = AgglomerativeClustering(n_clusters=5)\n.fit(df[['Fractal Dimension','Compression Eficciency']].values)\ndf[\"cluster\"] = clustering.labels_\n\n# Plotting results\nfig, ax = plt.subplots()\ncmap = cm.get_cmap('gist_rainbow')\nax = df.plot(kind='scatter', x='Fractal Dimension',\n\ty='Compression Eficciency',\n\tcmap=cmap, c='cluster',ax=ax)\nplt.show()\n```\n![descarga (5).png](https://ucarecdn.com/4fe8f003-2d3f-4296-8c24-9283bb587e2b/)\n\n## Results\nHere I show some samples of each cluster. I sorted them from the simplest ones to the most complex. As you can see this method is useful to identify and discard uninteresting patterns such us the ones from the Cluster 0. It's also useful to identify the most beautiful patterns, most of the best patterns I found are from the Cluster 3, the one with big complexity but not the biggest fractal dimension.\n\n### Cluster 0 (Null patterns)\n![descarga.png](https://ucarecdn.com/6f41e3ce-45dd-4b8e-aa00-b96fde1f09b4/)\n\n### Cluster 1\n![descarga (1).png](https://ucarecdn.com/565971db-1047-4100-92aa-c4feca3697ef/)\n\n### Cluster 2\n<img src=\"https://ucarecdn.com/98775929-3cdc-4ff7-8dbb-0038663896bd/\" width=\"100%\" border=\"5\" />\n\n### Cluster 3\n<img src=\"https://ucarecdn.com/8f4a6dcf-b501-4b8a-bcc0-0b4822b6c26e/\" width=\"100%\" border=\"5\" />\n\n### Cluster 4 (Crazy and chaotic patterns)\n<img src=\"https://ucarecdn.com/b7066ecc-a054-4d34-9ec6-e9ef521fad85/\" width=\"100%\" border=\"5\" />\n","slug":"Looking-for-the-beauty-formula","published":1,"updated":"2020-04-18T20:22:04.833Z","_id":"ck8m56ono00088gry11wsdl2c","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Some time ago I created <a href=\"https://gist.github.com/mathigatti/439a0e81556f2698c7db4f41189d201f\" target=\"_blank\" rel=\"noopener\">this</a> small script to convert numbers into patterns. I’m not going to explain how the script works in detail but it’s inspired on <a href=\"https://en.wikipedia.org/wiki/Elementary_cellular_automaton\" target=\"_blank\" rel=\"noopener\">Stephen Wolfram’s Elementary Cellular Automatas</a> which converts numbers like 30 into binary (00011110) and then interprets the digits as turning ON or OFF of 8 different basic rules (In that case there are 4 rules activated, rule 4, 5, 6 and 7) that define when to turn ON and OFF a pixel in the image.</p>\n<p><img src=\"https://ucarecdn.com/a4323adb-4c13-4c4f-a32d-97f86468a1f0/\" alt=\"ElementaryCARule030_1000.gif\"></p>\n<p>Using this I can generate an infinite number of different patterns, the problem is that most of them are not really interesting and I have no time to check them one by one. That’s why in this post I explain how I tried to automate the process of finding out the most interesting/beautiful cellular automatas.</p>\n<h2 id=\"Clusterization\"><a href=\"#Clusterization\" class=\"headerlink\" title=\"Clusterization\"></a>Clusterization</h2><p>My goal is to group the patterns by its beauty. I do this using a clustering algorithm based on features frequently attributed to beauty such as fractal dimensionality and compression efficiency. You can read more about these features here: <a href=\"https://www.researchgate.net/publication/49761486_Predicting_beauty_Fractal_dimension_and_visual_complexity_in_art\" target=\"_blank\" rel=\"noopener\">Forsythe, Alex, et al. “Predicting beauty: fractal dimension and visual complexity in art.” British journal of psychology 102.1 (2011): 49-70</a>.</p>\n<h2 id=\"The-Code\"><a href=\"#The-Code\" class=\"headerlink\" title=\"The Code\"></a>The Code</h2><p>The full code is <a href=\"https://github.com/mathigatti/CellularAutomataClassification\" target=\"_blank\" rel=\"noopener\">here</a> but I also uploaded it into colab <a href=\"https://colab.research.google.com/drive/1FFNRZuRW7lkKi1LnbMR-d8KI0EADl871\" target=\"_blank\" rel=\"noopener\">here</a> so you can run everything from your web browser.</p>\n<h3 id=\"Defining-clustering-attributes\"><a href=\"#Defining-clustering-attributes\" class=\"headerlink\" title=\"Defining clustering attributes\"></a>Defining clustering attributes</h3><p>First I define the previously mentioned attributes, fractal dimension (Code taken from <a href=\"https://gist.github.com/rougier/e5eafc276a4e54f516ed5559df4242c0\" target=\"_blank\" rel=\"noopener\">here</a>) and compression score (The weight of a raw tiff image over its weight compressed as a gif image).</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from fractaldimension import fractal_dimension</span><br><span class=\"line\">import cv2</span><br><span class=\"line\">import os</span><br><span class=\"line\"></span><br><span class=\"line\">def fractalDimension(number):</span><br><span class=\"line\">    im &#x3D; cv2.imread(&#39;images&#x2F;&#39;+str(number)+&#39;.tiff&#39;,</span><br><span class=\"line\">    cv2.IMREAD_GRAYSCALE)</span><br><span class=\"line\">    newDimension &#x3D; fractal_dimension(im, 0.9)</span><br><span class=\"line\">    return newDimension</span><br><span class=\"line\"></span><br><span class=\"line\">def compressionScore(number):</span><br><span class=\"line\">    statinfo &#x3D; os.stat(&#39;images&#x2F;&#39;+str(number)+&#39;.gif&#39;)</span><br><span class=\"line\">    gif &#x3D; statinfo.st_size # size of the file</span><br><span class=\"line\">    </span><br><span class=\"line\">    statinfo &#x3D; os.stat(&#39;images&#x2F;&#39;+str(number)+&#39;.tiff&#39;)</span><br><span class=\"line\">    tiff &#x3D; statinfo.st_size # size of the file</span><br><span class=\"line\">    </span><br><span class=\"line\">    return tiff&#x2F;gif</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Clustering\"><a href=\"#Clustering\" class=\"headerlink\" title=\"Clustering\"></a>Clustering</h3><p>There are several clustering algorithms, you can choose the one that best fits your use case.</p>\n<img src=\"https://ucarecdn.com/a6d86443-9072-44f0-b032-ccede2fe4073/\" width=\"100%\" border=\"5\" />\n\n<p>In my case I ended up using Agglomerative Clustering which captures better the clusters generated by this dataset.</p>\n<p>You need to specify the number of clusters, I tried with different numbers, at the end I chose 5 since it grouped them well from null patterns to crazy and chaotic ones.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from sklearn.cluster import AgglomerativeClustering</span><br><span class=\"line\">import matplotlib.pyplot as plt</span><br><span class=\"line\">from matplotlib import cm</span><br><span class=\"line\"></span><br><span class=\"line\"># Applying clustering algorithm</span><br><span class=\"line\">clustering &#x3D; AgglomerativeClustering(n_clusters&#x3D;5)</span><br><span class=\"line\">.fit(df[[&#39;Fractal Dimension&#39;,&#39;Compression Eficciency&#39;]].values)</span><br><span class=\"line\">df[&quot;cluster&quot;] &#x3D; clustering.labels_</span><br><span class=\"line\"></span><br><span class=\"line\"># Plotting results</span><br><span class=\"line\">fig, ax &#x3D; plt.subplots()</span><br><span class=\"line\">cmap &#x3D; cm.get_cmap(&#39;gist_rainbow&#39;)</span><br><span class=\"line\">ax &#x3D; df.plot(kind&#x3D;&#39;scatter&#39;, x&#x3D;&#39;Fractal Dimension&#39;,</span><br><span class=\"line\">\ty&#x3D;&#39;Compression Eficciency&#39;,</span><br><span class=\"line\">\tcmap&#x3D;cmap, c&#x3D;&#39;cluster&#39;,ax&#x3D;ax)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://ucarecdn.com/4fe8f003-2d3f-4296-8c24-9283bb587e2b/\" alt=\"descarga (5).png\"></p>\n<h2 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results\"></a>Results</h2><p>Here I show some samples of each cluster. I sorted them from the simplest ones to the most complex. As you can see this method is useful to identify and discard uninteresting patterns such us the ones from the Cluster 0. It’s also useful to identify the most beautiful patterns, most of the best patterns I found are from the Cluster 3, the one with big complexity but not the biggest fractal dimension.</p>\n<h3 id=\"Cluster-0-Null-patterns\"><a href=\"#Cluster-0-Null-patterns\" class=\"headerlink\" title=\"Cluster 0 (Null patterns)\"></a>Cluster 0 (Null patterns)</h3><p><img src=\"https://ucarecdn.com/6f41e3ce-45dd-4b8e-aa00-b96fde1f09b4/\" alt=\"descarga.png\"></p>\n<h3 id=\"Cluster-1\"><a href=\"#Cluster-1\" class=\"headerlink\" title=\"Cluster 1\"></a>Cluster 1</h3><p><img src=\"https://ucarecdn.com/565971db-1047-4100-92aa-c4feca3697ef/\" alt=\"descarga (1).png\"></p>\n<h3 id=\"Cluster-2\"><a href=\"#Cluster-2\" class=\"headerlink\" title=\"Cluster 2\"></a>Cluster 2</h3><img src=\"https://ucarecdn.com/98775929-3cdc-4ff7-8dbb-0038663896bd/\" width=\"100%\" border=\"5\" />\n\n<h3 id=\"Cluster-3\"><a href=\"#Cluster-3\" class=\"headerlink\" title=\"Cluster 3\"></a>Cluster 3</h3><img src=\"https://ucarecdn.com/8f4a6dcf-b501-4b8a-bcc0-0b4822b6c26e/\" width=\"100%\" border=\"5\" />\n\n<h3 id=\"Cluster-4-Crazy-and-chaotic-patterns\"><a href=\"#Cluster-4-Crazy-and-chaotic-patterns\" class=\"headerlink\" title=\"Cluster 4 (Crazy and chaotic patterns)\"></a>Cluster 4 (Crazy and chaotic patterns)</h3><img src=\"https://ucarecdn.com/b7066ecc-a054-4d34-9ec6-e9ef521fad85/\" width=\"100%\" border=\"5\" />\n","site":{"data":{}},"excerpt":"","more":"<p>Some time ago I created <a href=\"https://gist.github.com/mathigatti/439a0e81556f2698c7db4f41189d201f\" target=\"_blank\" rel=\"noopener\">this</a> small script to convert numbers into patterns. I’m not going to explain how the script works in detail but it’s inspired on <a href=\"https://en.wikipedia.org/wiki/Elementary_cellular_automaton\" target=\"_blank\" rel=\"noopener\">Stephen Wolfram’s Elementary Cellular Automatas</a> which converts numbers like 30 into binary (00011110) and then interprets the digits as turning ON or OFF of 8 different basic rules (In that case there are 4 rules activated, rule 4, 5, 6 and 7) that define when to turn ON and OFF a pixel in the image.</p>\n<p><img src=\"https://ucarecdn.com/a4323adb-4c13-4c4f-a32d-97f86468a1f0/\" alt=\"ElementaryCARule030_1000.gif\"></p>\n<p>Using this I can generate an infinite number of different patterns, the problem is that most of them are not really interesting and I have no time to check them one by one. That’s why in this post I explain how I tried to automate the process of finding out the most interesting/beautiful cellular automatas.</p>\n<h2 id=\"Clusterization\"><a href=\"#Clusterization\" class=\"headerlink\" title=\"Clusterization\"></a>Clusterization</h2><p>My goal is to group the patterns by its beauty. I do this using a clustering algorithm based on features frequently attributed to beauty such as fractal dimensionality and compression efficiency. You can read more about these features here: <a href=\"https://www.researchgate.net/publication/49761486_Predicting_beauty_Fractal_dimension_and_visual_complexity_in_art\" target=\"_blank\" rel=\"noopener\">Forsythe, Alex, et al. “Predicting beauty: fractal dimension and visual complexity in art.” British journal of psychology 102.1 (2011): 49-70</a>.</p>\n<h2 id=\"The-Code\"><a href=\"#The-Code\" class=\"headerlink\" title=\"The Code\"></a>The Code</h2><p>The full code is <a href=\"https://github.com/mathigatti/CellularAutomataClassification\" target=\"_blank\" rel=\"noopener\">here</a> but I also uploaded it into colab <a href=\"https://colab.research.google.com/drive/1FFNRZuRW7lkKi1LnbMR-d8KI0EADl871\" target=\"_blank\" rel=\"noopener\">here</a> so you can run everything from your web browser.</p>\n<h3 id=\"Defining-clustering-attributes\"><a href=\"#Defining-clustering-attributes\" class=\"headerlink\" title=\"Defining clustering attributes\"></a>Defining clustering attributes</h3><p>First I define the previously mentioned attributes, fractal dimension (Code taken from <a href=\"https://gist.github.com/rougier/e5eafc276a4e54f516ed5559df4242c0\" target=\"_blank\" rel=\"noopener\">here</a>) and compression score (The weight of a raw tiff image over its weight compressed as a gif image).</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from fractaldimension import fractal_dimension</span><br><span class=\"line\">import cv2</span><br><span class=\"line\">import os</span><br><span class=\"line\"></span><br><span class=\"line\">def fractalDimension(number):</span><br><span class=\"line\">    im &#x3D; cv2.imread(&#39;images&#x2F;&#39;+str(number)+&#39;.tiff&#39;,</span><br><span class=\"line\">    cv2.IMREAD_GRAYSCALE)</span><br><span class=\"line\">    newDimension &#x3D; fractal_dimension(im, 0.9)</span><br><span class=\"line\">    return newDimension</span><br><span class=\"line\"></span><br><span class=\"line\">def compressionScore(number):</span><br><span class=\"line\">    statinfo &#x3D; os.stat(&#39;images&#x2F;&#39;+str(number)+&#39;.gif&#39;)</span><br><span class=\"line\">    gif &#x3D; statinfo.st_size # size of the file</span><br><span class=\"line\">    </span><br><span class=\"line\">    statinfo &#x3D; os.stat(&#39;images&#x2F;&#39;+str(number)+&#39;.tiff&#39;)</span><br><span class=\"line\">    tiff &#x3D; statinfo.st_size # size of the file</span><br><span class=\"line\">    </span><br><span class=\"line\">    return tiff&#x2F;gif</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Clustering\"><a href=\"#Clustering\" class=\"headerlink\" title=\"Clustering\"></a>Clustering</h3><p>There are several clustering algorithms, you can choose the one that best fits your use case.</p>\n<img src=\"https://ucarecdn.com/a6d86443-9072-44f0-b032-ccede2fe4073/\" width=\"100%\" border=\"5\" />\n\n<p>In my case I ended up using Agglomerative Clustering which captures better the clusters generated by this dataset.</p>\n<p>You need to specify the number of clusters, I tried with different numbers, at the end I chose 5 since it grouped them well from null patterns to crazy and chaotic ones.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from sklearn.cluster import AgglomerativeClustering</span><br><span class=\"line\">import matplotlib.pyplot as plt</span><br><span class=\"line\">from matplotlib import cm</span><br><span class=\"line\"></span><br><span class=\"line\"># Applying clustering algorithm</span><br><span class=\"line\">clustering &#x3D; AgglomerativeClustering(n_clusters&#x3D;5)</span><br><span class=\"line\">.fit(df[[&#39;Fractal Dimension&#39;,&#39;Compression Eficciency&#39;]].values)</span><br><span class=\"line\">df[&quot;cluster&quot;] &#x3D; clustering.labels_</span><br><span class=\"line\"></span><br><span class=\"line\"># Plotting results</span><br><span class=\"line\">fig, ax &#x3D; plt.subplots()</span><br><span class=\"line\">cmap &#x3D; cm.get_cmap(&#39;gist_rainbow&#39;)</span><br><span class=\"line\">ax &#x3D; df.plot(kind&#x3D;&#39;scatter&#39;, x&#x3D;&#39;Fractal Dimension&#39;,</span><br><span class=\"line\">\ty&#x3D;&#39;Compression Eficciency&#39;,</span><br><span class=\"line\">\tcmap&#x3D;cmap, c&#x3D;&#39;cluster&#39;,ax&#x3D;ax)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://ucarecdn.com/4fe8f003-2d3f-4296-8c24-9283bb587e2b/\" alt=\"descarga (5).png\"></p>\n<h2 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results\"></a>Results</h2><p>Here I show some samples of each cluster. I sorted them from the simplest ones to the most complex. As you can see this method is useful to identify and discard uninteresting patterns such us the ones from the Cluster 0. It’s also useful to identify the most beautiful patterns, most of the best patterns I found are from the Cluster 3, the one with big complexity but not the biggest fractal dimension.</p>\n<h3 id=\"Cluster-0-Null-patterns\"><a href=\"#Cluster-0-Null-patterns\" class=\"headerlink\" title=\"Cluster 0 (Null patterns)\"></a>Cluster 0 (Null patterns)</h3><p><img src=\"https://ucarecdn.com/6f41e3ce-45dd-4b8e-aa00-b96fde1f09b4/\" alt=\"descarga.png\"></p>\n<h3 id=\"Cluster-1\"><a href=\"#Cluster-1\" class=\"headerlink\" title=\"Cluster 1\"></a>Cluster 1</h3><p><img src=\"https://ucarecdn.com/565971db-1047-4100-92aa-c4feca3697ef/\" alt=\"descarga (1).png\"></p>\n<h3 id=\"Cluster-2\"><a href=\"#Cluster-2\" class=\"headerlink\" title=\"Cluster 2\"></a>Cluster 2</h3><img src=\"https://ucarecdn.com/98775929-3cdc-4ff7-8dbb-0038663896bd/\" width=\"100%\" border=\"5\" />\n\n<h3 id=\"Cluster-3\"><a href=\"#Cluster-3\" class=\"headerlink\" title=\"Cluster 3\"></a>Cluster 3</h3><img src=\"https://ucarecdn.com/8f4a6dcf-b501-4b8a-bcc0-0b4822b6c26e/\" width=\"100%\" border=\"5\" />\n\n<h3 id=\"Cluster-4-Crazy-and-chaotic-patterns\"><a href=\"#Cluster-4-Crazy-and-chaotic-patterns\" class=\"headerlink\" title=\"Cluster 4 (Crazy and chaotic patterns)\"></a>Cluster 4 (Crazy and chaotic patterns)</h3><img src=\"https://ucarecdn.com/b7066ecc-a054-4d34-9ec6-e9ef521fad85/\" width=\"100%\" border=\"5\" />\n"},{"title":"Scraping drum patterns from PDF","date":"2020-02-20T21:48:17.000Z","summary":"Big collection of digitalized drum patterns","_content":"\nPocket JSON Ops is a rhythm dictionary taken from the book [Pocket Operations](https://b.shittyrecording.studio/file/shittyrec/print/Pocket+Operations+(2019-07-01).pdf), which compiles different percussion rhythms.\n\n![alt text](https://github.com/bu3nAmigue/pocket-json-ops/raw/master/pattern_example.jpg)\n\n\n## Why we did this?\n\nIn order to use the different rhythms compiled with different livecoding languages, convert the PDF into a beautiful JSON for the modern music computer. This was generated from an HTML version, generated from the PDF, and then analyzed using the Python Beautiful Soup 4 library.\n\n## How to listen the patterns?\n\nThe `dpattern2foxdot.py` script contains an example of how patterns can be read and reproduced within FoxDot, Python's live music framework.","source":"_posts/Scraping-drum-patterns-from-PDF.md","raw":"---\ntitle: Scraping drum patterns from PDF\ndate: 2020-02-20 18:48:17\ntags:\nsummary: Big collection of digitalized drum patterns\n---\n\nPocket JSON Ops is a rhythm dictionary taken from the book [Pocket Operations](https://b.shittyrecording.studio/file/shittyrec/print/Pocket+Operations+(2019-07-01).pdf), which compiles different percussion rhythms.\n\n![alt text](https://github.com/bu3nAmigue/pocket-json-ops/raw/master/pattern_example.jpg)\n\n\n## Why we did this?\n\nIn order to use the different rhythms compiled with different livecoding languages, convert the PDF into a beautiful JSON for the modern music computer. This was generated from an HTML version, generated from the PDF, and then analyzed using the Python Beautiful Soup 4 library.\n\n## How to listen the patterns?\n\nThe `dpattern2foxdot.py` script contains an example of how patterns can be read and reproduced within FoxDot, Python's live music framework.","slug":"Scraping-drum-patterns-from-PDF","published":1,"updated":"2020-05-10T01:24:50.732Z","_id":"ck8m5f2h2000b8gry1scq4eik","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Pocket JSON Ops is a rhythm dictionary taken from the book <a href=\"https://b.shittyrecording.studio/file/shittyrec/print/Pocket+Operations+(2019-07-01).pdf\" target=\"_blank\" rel=\"noopener\">Pocket Operations</a>, which compiles different percussion rhythms.</p>\n<p><img src=\"https://github.com/bu3nAmigue/pocket-json-ops/raw/master/pattern_example.jpg\" alt=\"alt text\"></p>\n<h2 id=\"Why-we-did-this\"><a href=\"#Why-we-did-this\" class=\"headerlink\" title=\"Why we did this?\"></a>Why we did this?</h2><p>In order to use the different rhythms compiled with different livecoding languages, convert the PDF into a beautiful JSON for the modern music computer. This was generated from an HTML version, generated from the PDF, and then analyzed using the Python Beautiful Soup 4 library.</p>\n<h2 id=\"How-to-listen-the-patterns\"><a href=\"#How-to-listen-the-patterns\" class=\"headerlink\" title=\"How to listen the patterns?\"></a>How to listen the patterns?</h2><p>The <code>dpattern2foxdot.py</code> script contains an example of how patterns can be read and reproduced within FoxDot, Python’s live music framework.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Pocket JSON Ops is a rhythm dictionary taken from the book <a href=\"https://b.shittyrecording.studio/file/shittyrec/print/Pocket+Operations+(2019-07-01).pdf\" target=\"_blank\" rel=\"noopener\">Pocket Operations</a>, which compiles different percussion rhythms.</p>\n<p><img src=\"https://github.com/bu3nAmigue/pocket-json-ops/raw/master/pattern_example.jpg\" alt=\"alt text\"></p>\n<h2 id=\"Why-we-did-this\"><a href=\"#Why-we-did-this\" class=\"headerlink\" title=\"Why we did this?\"></a>Why we did this?</h2><p>In order to use the different rhythms compiled with different livecoding languages, convert the PDF into a beautiful JSON for the modern music computer. This was generated from an HTML version, generated from the PDF, and then analyzed using the Python Beautiful Soup 4 library.</p>\n<h2 id=\"How-to-listen-the-patterns\"><a href=\"#How-to-listen-the-patterns\" class=\"headerlink\" title=\"How to listen the patterns?\"></a>How to listen the patterns?</h2><p>The <code>dpattern2foxdot.py</code> script contains an example of how patterns can be read and reproduced within FoxDot, Python’s live music framework.</p>\n"}],"PostAsset":[{"_id":"source/_posts/number2image/pattern.png","slug":"pattern.png","post":"ck8hi88zu000085ry9tkg2461","modified":0,"renderable":0},{"_id":"source/_posts/jardin-sonoro/inicio.png","slug":"inicio.png","post":"ck8hj4b4c00024zry4lyp1yut","modified":0,"renderable":0},{"_id":"source/_posts/jardin-sonoro/load.png","slug":"load.png","post":"ck8hj4b4c00024zry4lyp1yut","modified":0,"renderable":0},{"_id":"source/_posts/jardin-sonoro/player.png","slug":"player.png","post":"ck8hj4b4c00024zry4lyp1yut","modified":0,"renderable":0},{"_id":"source/_posts/Midi-to-Voice/shallow.jpg","slug":"shallow.jpg","post":"ck8jb761i0003nlrybwo7gr1d","modified":0,"renderable":0},{"_id":"source/_posts/Audio-Reactive-Slime/physarum.jpg","slug":"physarum.jpg","post":"ck8jb761d0000nlry8cv13tw7","modified":0,"renderable":0},{"_id":"source/_posts/Audio-Reactive-Slime/physarum2.jpg","slug":"physarum2.jpg","post":"ck8jb761d0000nlry8cv13tw7","modified":0,"renderable":0},{"_id":"source/_posts/AI-Poem-Writer/english3.jpg","slug":"english3.jpg","post":"ck8jb761h0002nlryden35kvr","modified":0,"renderable":0},{"_id":"source/_posts/AI-Poem-Writer/english2.jpg","slug":"english2.jpg","post":"ck8jb761h0002nlryden35kvr","modified":0,"renderable":0},{"_id":"source/_posts/AI-Poem-Writer/english1.jpg","slug":"english1.jpg","post":"ck8jb761h0002nlryden35kvr","modified":0,"renderable":0},{"_id":"source/_posts/AI-Poem-Writer/spanish3.jpg","slug":"spanish3.jpg","post":"ck8jb761h0002nlryden35kvr","modified":0,"renderable":0},{"_id":"source/_posts/AI-Poem-Writer/spanish2.jpg","slug":"spanish2.jpg","post":"ck8jb761h0002nlryden35kvr","modified":0,"renderable":0},{"_id":"source/_posts/AI-Poem-Writer/spanish1.jpg","slug":"spanish1.jpg","post":"ck8jb761h0002nlryden35kvr","modified":0,"renderable":0},{"_id":"source/_posts/Regenerative-cellular-automata/automata1.gif","slug":"automata1.gif","post":"ck8jb761k0005nlry965w6k6l","modified":0,"renderable":0},{"_id":"source/_posts/Regenerative-cellular-automata/automata2.gif","slug":"automata2.gif","post":"ck8jb761k0005nlry965w6k6l","modified":0,"renderable":0},{"_id":"source/_posts/Style-Transfer-Experiments/s1_2.jpg","slug":"s1_2.jpg","post":"ck8jb761m0007nlry4nk76xpp","modified":0,"renderable":0},{"_id":"source/_posts/Style-Transfer-Experiments/s1_3.jpg","slug":"s1_3.jpg","post":"ck8jb761m0007nlry4nk76xpp","modified":0,"renderable":0},{"_id":"source/_posts/Style-Transfer-Experiments/s1_4.jpg","slug":"s1_4.jpg","post":"ck8jb761m0007nlry4nk76xpp","modified":0,"renderable":0},{"_id":"source/_posts/Style-Transfer-Experiments/s2_1.jpg","slug":"s2_1.jpg","post":"ck8jb761m0007nlry4nk76xpp","modified":0,"renderable":0},{"_id":"source/_posts/Style-Transfer-Experiments/s2_2.jpg","slug":"s2_2.jpg","post":"ck8jb761m0007nlry4nk76xpp","modified":0,"renderable":0},{"_id":"source/_posts/Style-Transfer-Experiments/s2_3.jpg","slug":"s2_3.jpg","post":"ck8jb761m0007nlry4nk76xpp","modified":0,"renderable":0},{"_id":"source/_posts/Style-Transfer-Experiments/s2_4.jpg","slug":"s2_4.jpg","post":"ck8jb761m0007nlry4nk76xpp","modified":0,"renderable":0},{"_id":"source/_posts/Style-Transfer-Experiments/s3_1.jpg","slug":"s3_1.jpg","post":"ck8jb761m0007nlry4nk76xpp","modified":0,"renderable":0},{"_id":"source/_posts/Style-Transfer-Experiments/s3_2.jpg","slug":"s3_2.jpg","post":"ck8jb761m0007nlry4nk76xpp","modified":0,"renderable":0},{"_id":"source/_posts/Style-Transfer-Experiments/s4_1.jpg","slug":"s4_1.jpg","post":"ck8jb761m0007nlry4nk76xpp","modified":0,"renderable":0},{"_id":"source/_posts/Style-Transfer-Experiments/s4_2.jpg","slug":"s4_2.jpg","post":"ck8jb761m0007nlry4nk76xpp","modified":0,"renderable":0},{"_id":"source/_posts/Style-Transfer-Experiments/s1_1.jpg","slug":"s1_1.jpg","post":"ck8jb761m0007nlry4nk76xpp","modified":0,"renderable":0},{"_id":"source/_posts/Computing-brain-connectivity-using-portable-devices-Master-s-Thesis/emotiv.jpg","slug":"emotiv.jpg","post":"ck8m55ato00078gry1hg55s8h","modified":0,"renderable":0},{"_id":"source/_posts/Audio-Reactive-Slime/physarum.gif","slug":"physarum.gif","post":"ck8jb761d0000nlry8cv13tw7","modified":0,"renderable":0}],"PostCategory":[],"PostTag":[{"post_id":"ck8jb761h0002nlryden35kvr","tag_id":"ck8m46kjc00008gry85m0dmyj","_id":"ck8m46kje00018gryd32fb6wj"},{"post_id":"ck8jb761l0006nlryb17b2n5h","tag_id":"ck8m4kqvi00028gry0vu6hecu","_id":"ck8m4kqvk00038gry76a70dto"},{"post_id":"ck8jb761m0007nlry4nk76xpp","tag_id":"ck8m500pq00048gry8eofb5oz","_id":"ck8m500pr00058gryaj04fcwj"},{"post_id":"ck8m56ono00088gry11wsdl2c","tag_id":"ck8m5cdl200098gry42nz5eep","_id":"ck8m5cdl3000a8grybu8ea4ig"},{"post_id":"ck8m55ato00078gry1hg55s8h","tag_id":"ck8m5yjdl000c8gryghmoeebd","_id":"ck8m5yjdm000d8gryad0h18k5"}],"Tag":[{"name":"poetry, gpt-2","_id":"ck8m46kjc00008gry85m0dmyj"},{"name":"ocr","_id":"ck8m4kqvi00028gry0vu6hecu"},{"name":"style-transfer","_id":"ck8m500pq00048gry8eofb5oz"},{"name":"cellular-automata","_id":"ck8m5cdl200098gry42nz5eep"},{"name":"neuroscience","_id":"ck8m5yjdl000c8gryghmoeebd"}]}}